{
  "best_global_step": 900,
  "best_metric": 0.9905650399999999,
  "best_model_checkpoint": "./saved_models/mistral_raid_detector_adapter/checkpoint-500",
  "epoch": 0.7111111111111111,
  "eval_steps": 100,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0035555555555555557,
      "grad_norm": 71.04328918457031,
      "learning_rate": 1.1363636363636364e-07,
      "loss": 3.199,
      "step": 5
    },
    {
      "epoch": 0.0071111111111111115,
      "grad_norm": 93.5253677368164,
      "learning_rate": 2.556818181818182e-07,
      "loss": 4.053,
      "step": 10
    },
    {
      "epoch": 0.010666666666666666,
      "grad_norm": 88.8437728881836,
      "learning_rate": 3.9772727272727276e-07,
      "loss": 3.4953,
      "step": 15
    },
    {
      "epoch": 0.014222222222222223,
      "grad_norm": 77.8512191772461,
      "learning_rate": 5.397727272727273e-07,
      "loss": 3.4161,
      "step": 20
    },
    {
      "epoch": 0.017777777777777778,
      "grad_norm": 83.5049057006836,
      "learning_rate": 6.818181818181818e-07,
      "loss": 3.3839,
      "step": 25
    },
    {
      "epoch": 0.021333333333333333,
      "grad_norm": 107.94293975830078,
      "learning_rate": 8.238636363636364e-07,
      "loss": 3.2606,
      "step": 30
    },
    {
      "epoch": 0.024888888888888887,
      "grad_norm": 102.4188003540039,
      "learning_rate": 9.65909090909091e-07,
      "loss": 3.259,
      "step": 35
    },
    {
      "epoch": 0.028444444444444446,
      "grad_norm": 86.81859588623047,
      "learning_rate": 1.1079545454545456e-06,
      "loss": 3.7254,
      "step": 40
    },
    {
      "epoch": 0.032,
      "grad_norm": 79.50184631347656,
      "learning_rate": 1.25e-06,
      "loss": 3.6664,
      "step": 45
    },
    {
      "epoch": 0.035555555555555556,
      "grad_norm": 88.2386245727539,
      "learning_rate": 1.3920454545454546e-06,
      "loss": 3.1795,
      "step": 50
    },
    {
      "epoch": 0.03911111111111111,
      "grad_norm": 80.6746826171875,
      "learning_rate": 1.5340909090909093e-06,
      "loss": 3.6724,
      "step": 55
    },
    {
      "epoch": 0.042666666666666665,
      "grad_norm": 107.36078643798828,
      "learning_rate": 1.6761363636363636e-06,
      "loss": 3.5076,
      "step": 60
    },
    {
      "epoch": 0.04622222222222222,
      "grad_norm": 63.777278900146484,
      "learning_rate": 1.8181818181818183e-06,
      "loss": 3.4842,
      "step": 65
    },
    {
      "epoch": 0.049777777777777775,
      "grad_norm": 75.39788055419922,
      "learning_rate": 1.9602272727272728e-06,
      "loss": 3.3059,
      "step": 70
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 94.22563934326172,
      "learning_rate": 2.1022727272727277e-06,
      "loss": 3.0093,
      "step": 75
    },
    {
      "epoch": 0.05688888888888889,
      "grad_norm": 99.65691375732422,
      "learning_rate": 2.2443181818181818e-06,
      "loss": 2.9073,
      "step": 80
    },
    {
      "epoch": 0.060444444444444446,
      "grad_norm": 92.19189453125,
      "learning_rate": 2.3863636363636367e-06,
      "loss": 3.5358,
      "step": 85
    },
    {
      "epoch": 0.064,
      "grad_norm": 73.14012908935547,
      "learning_rate": 2.528409090909091e-06,
      "loss": 3.9857,
      "step": 90
    },
    {
      "epoch": 0.06755555555555555,
      "grad_norm": 81.0314712524414,
      "learning_rate": 2.6704545454545457e-06,
      "loss": 3.5816,
      "step": 95
    },
    {
      "epoch": 0.07111111111111111,
      "grad_norm": 76.77008056640625,
      "learning_rate": 2.8125e-06,
      "loss": 3.1228,
      "step": 100
    },
    {
      "epoch": 0.07111111111111111,
      "eval_accuracy": 0.5416,
      "eval_f1": 0.5466772151898733,
      "eval_loss": 3.3244566917419434,
      "eval_precision": 0.5406885758998435,
      "eval_recall": 0.5528,
      "eval_roc_auc": 0.55644768,
      "eval_runtime": 617.4876,
      "eval_samples_per_second": 8.097,
      "eval_steps_per_second": 0.507,
      "step": 100
    },
    {
      "epoch": 0.07466666666666667,
      "grad_norm": 88.65370178222656,
      "learning_rate": 2.954545454545455e-06,
      "loss": 3.8884,
      "step": 105
    },
    {
      "epoch": 0.07822222222222222,
      "grad_norm": 111.03863525390625,
      "learning_rate": 3.096590909090909e-06,
      "loss": 3.6717,
      "step": 110
    },
    {
      "epoch": 0.08177777777777778,
      "grad_norm": 74.07740783691406,
      "learning_rate": 3.2386363636363637e-06,
      "loss": 3.3696,
      "step": 115
    },
    {
      "epoch": 0.08533333333333333,
      "grad_norm": 62.01462173461914,
      "learning_rate": 3.3806818181818186e-06,
      "loss": 3.09,
      "step": 120
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 60.25017166137695,
      "learning_rate": 3.522727272727273e-06,
      "loss": 2.5665,
      "step": 125
    },
    {
      "epoch": 0.09244444444444444,
      "grad_norm": 83.81108093261719,
      "learning_rate": 3.6647727272727276e-06,
      "loss": 2.8816,
      "step": 130
    },
    {
      "epoch": 0.096,
      "grad_norm": 78.8825454711914,
      "learning_rate": 3.806818181818182e-06,
      "loss": 2.6929,
      "step": 135
    },
    {
      "epoch": 0.09955555555555555,
      "grad_norm": 58.09162139892578,
      "learning_rate": 3.9488636363636366e-06,
      "loss": 2.9076,
      "step": 140
    },
    {
      "epoch": 0.10311111111111111,
      "grad_norm": 71.34232330322266,
      "learning_rate": 4.0909090909090915e-06,
      "loss": 2.8492,
      "step": 145
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 74.09046173095703,
      "learning_rate": 4.2329545454545455e-06,
      "loss": 2.5419,
      "step": 150
    },
    {
      "epoch": 0.11022222222222222,
      "grad_norm": 63.935787200927734,
      "learning_rate": 4.3750000000000005e-06,
      "loss": 2.072,
      "step": 155
    },
    {
      "epoch": 0.11377777777777778,
      "grad_norm": 79.86321258544922,
      "learning_rate": 4.517045454545455e-06,
      "loss": 2.7848,
      "step": 160
    },
    {
      "epoch": 0.11733333333333333,
      "grad_norm": 77.87474822998047,
      "learning_rate": 4.6590909090909095e-06,
      "loss": 2.0533,
      "step": 165
    },
    {
      "epoch": 0.12088888888888889,
      "grad_norm": 90.08426666259766,
      "learning_rate": 4.8011363636363635e-06,
      "loss": 2.4981,
      "step": 170
    },
    {
      "epoch": 0.12444444444444444,
      "grad_norm": 64.60723876953125,
      "learning_rate": 4.9431818181818184e-06,
      "loss": 2.1348,
      "step": 175
    },
    {
      "epoch": 0.128,
      "grad_norm": 63.45016860961914,
      "learning_rate": 5.085227272727273e-06,
      "loss": 1.2775,
      "step": 180
    },
    {
      "epoch": 0.13155555555555556,
      "grad_norm": 56.58731460571289,
      "learning_rate": 5.2272727272727274e-06,
      "loss": 1.8711,
      "step": 185
    },
    {
      "epoch": 0.1351111111111111,
      "grad_norm": 55.79026794433594,
      "learning_rate": 5.369318181818182e-06,
      "loss": 1.6205,
      "step": 190
    },
    {
      "epoch": 0.13866666666666666,
      "grad_norm": 64.19409942626953,
      "learning_rate": 5.511363636363637e-06,
      "loss": 1.8185,
      "step": 195
    },
    {
      "epoch": 0.14222222222222222,
      "grad_norm": 68.09229278564453,
      "learning_rate": 5.653409090909091e-06,
      "loss": 1.9918,
      "step": 200
    },
    {
      "epoch": 0.14222222222222222,
      "eval_accuracy": 0.7336,
      "eval_f1": 0.7356093687971418,
      "eval_loss": 1.7695804834365845,
      "eval_precision": 0.7301024428684003,
      "eval_recall": 0.7412,
      "eval_roc_auc": 0.8016439200000001,
      "eval_runtime": 615.1134,
      "eval_samples_per_second": 8.129,
      "eval_steps_per_second": 0.509,
      "step": 200
    },
    {
      "epoch": 0.14577777777777778,
      "grad_norm": 50.9853515625,
      "learning_rate": 5.795454545454546e-06,
      "loss": 1.8334,
      "step": 205
    },
    {
      "epoch": 0.14933333333333335,
      "grad_norm": 54.55915451049805,
      "learning_rate": 5.9375e-06,
      "loss": 1.3688,
      "step": 210
    },
    {
      "epoch": 0.15288888888888888,
      "grad_norm": 53.107540130615234,
      "learning_rate": 6.079545454545454e-06,
      "loss": 2.0339,
      "step": 215
    },
    {
      "epoch": 0.15644444444444444,
      "grad_norm": 87.46237182617188,
      "learning_rate": 6.22159090909091e-06,
      "loss": 1.468,
      "step": 220
    },
    {
      "epoch": 0.16,
      "grad_norm": 76.26721954345703,
      "learning_rate": 6.363636363636364e-06,
      "loss": 1.0681,
      "step": 225
    },
    {
      "epoch": 0.16355555555555557,
      "grad_norm": 47.2247314453125,
      "learning_rate": 6.505681818181818e-06,
      "loss": 1.3088,
      "step": 230
    },
    {
      "epoch": 0.1671111111111111,
      "grad_norm": 72.8374252319336,
      "learning_rate": 6.647727272727273e-06,
      "loss": 1.3234,
      "step": 235
    },
    {
      "epoch": 0.17066666666666666,
      "grad_norm": 93.10860443115234,
      "learning_rate": 6.789772727272727e-06,
      "loss": 1.1386,
      "step": 240
    },
    {
      "epoch": 0.17422222222222222,
      "grad_norm": 70.82707977294922,
      "learning_rate": 6.931818181818183e-06,
      "loss": 1.5705,
      "step": 245
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 59.78190231323242,
      "learning_rate": 7.073863636363637e-06,
      "loss": 1.6872,
      "step": 250
    },
    {
      "epoch": 0.18133333333333335,
      "grad_norm": 56.15513610839844,
      "learning_rate": 7.215909090909091e-06,
      "loss": 1.356,
      "step": 255
    },
    {
      "epoch": 0.18488888888888888,
      "grad_norm": 52.503326416015625,
      "learning_rate": 7.357954545454546e-06,
      "loss": 1.1186,
      "step": 260
    },
    {
      "epoch": 0.18844444444444444,
      "grad_norm": 86.41956329345703,
      "learning_rate": 7.500000000000001e-06,
      "loss": 1.2311,
      "step": 265
    },
    {
      "epoch": 0.192,
      "grad_norm": 67.4327163696289,
      "learning_rate": 7.642045454545454e-06,
      "loss": 1.3418,
      "step": 270
    },
    {
      "epoch": 0.19555555555555557,
      "grad_norm": 44.249473571777344,
      "learning_rate": 7.784090909090911e-06,
      "loss": 1.0673,
      "step": 275
    },
    {
      "epoch": 0.1991111111111111,
      "grad_norm": 55.277565002441406,
      "learning_rate": 7.926136363636364e-06,
      "loss": 1.331,
      "step": 280
    },
    {
      "epoch": 0.20266666666666666,
      "grad_norm": 102.40503692626953,
      "learning_rate": 8.068181818181819e-06,
      "loss": 1.4487,
      "step": 285
    },
    {
      "epoch": 0.20622222222222222,
      "grad_norm": 95.21125793457031,
      "learning_rate": 8.210227272727274e-06,
      "loss": 1.3679,
      "step": 290
    },
    {
      "epoch": 0.20977777777777779,
      "grad_norm": 40.16487503051758,
      "learning_rate": 8.352272727272727e-06,
      "loss": 0.9609,
      "step": 295
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 62.939735412597656,
      "learning_rate": 8.494318181818184e-06,
      "loss": 1.2111,
      "step": 300
    },
    {
      "epoch": 0.21333333333333335,
      "eval_accuracy": 0.8368,
      "eval_f1": 0.8391801340165549,
      "eval_loss": 1.0403927564620972,
      "eval_precision": 0.8271173271173271,
      "eval_recall": 0.8516,
      "eval_roc_auc": 0.9212188000000001,
      "eval_runtime": 615.6218,
      "eval_samples_per_second": 8.122,
      "eval_steps_per_second": 0.508,
      "step": 300
    },
    {
      "epoch": 0.21688888888888888,
      "grad_norm": 66.02793884277344,
      "learning_rate": 8.636363636363637e-06,
      "loss": 1.0098,
      "step": 305
    },
    {
      "epoch": 0.22044444444444444,
      "grad_norm": 63.184356689453125,
      "learning_rate": 8.778409090909092e-06,
      "loss": 0.8753,
      "step": 310
    },
    {
      "epoch": 0.224,
      "grad_norm": 48.896644592285156,
      "learning_rate": 8.920454545454547e-06,
      "loss": 1.3269,
      "step": 315
    },
    {
      "epoch": 0.22755555555555557,
      "grad_norm": 62.976524353027344,
      "learning_rate": 9.0625e-06,
      "loss": 1.0106,
      "step": 320
    },
    {
      "epoch": 0.2311111111111111,
      "grad_norm": 48.09809494018555,
      "learning_rate": 9.204545454545455e-06,
      "loss": 0.9496,
      "step": 325
    },
    {
      "epoch": 0.23466666666666666,
      "grad_norm": 88.64533233642578,
      "learning_rate": 9.34659090909091e-06,
      "loss": 0.9618,
      "step": 330
    },
    {
      "epoch": 0.23822222222222222,
      "grad_norm": 40.25056838989258,
      "learning_rate": 9.488636363636365e-06,
      "loss": 0.75,
      "step": 335
    },
    {
      "epoch": 0.24177777777777779,
      "grad_norm": 58.73966979980469,
      "learning_rate": 9.630681818181818e-06,
      "loss": 0.8281,
      "step": 340
    },
    {
      "epoch": 0.24533333333333332,
      "grad_norm": 54.121482849121094,
      "learning_rate": 9.772727272727273e-06,
      "loss": 0.4321,
      "step": 345
    },
    {
      "epoch": 0.24888888888888888,
      "grad_norm": 49.83610916137695,
      "learning_rate": 9.914772727272728e-06,
      "loss": 1.0093,
      "step": 350
    },
    {
      "epoch": 0.25244444444444447,
      "grad_norm": 59.908878326416016,
      "learning_rate": 1.0056818181818183e-05,
      "loss": 0.7023,
      "step": 355
    },
    {
      "epoch": 0.256,
      "grad_norm": 55.440486907958984,
      "learning_rate": 1.0198863636363636e-05,
      "loss": 0.7911,
      "step": 360
    },
    {
      "epoch": 0.25955555555555554,
      "grad_norm": 20.477806091308594,
      "learning_rate": 1.0340909090909093e-05,
      "loss": 0.618,
      "step": 365
    },
    {
      "epoch": 0.26311111111111113,
      "grad_norm": 81.88351440429688,
      "learning_rate": 1.0482954545454548e-05,
      "loss": 0.9571,
      "step": 370
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 101.2985610961914,
      "learning_rate": 1.0625e-05,
      "loss": 0.5872,
      "step": 375
    },
    {
      "epoch": 0.2702222222222222,
      "grad_norm": 56.29861068725586,
      "learning_rate": 1.0767045454545456e-05,
      "loss": 0.6548,
      "step": 380
    },
    {
      "epoch": 0.2737777777777778,
      "grad_norm": 43.12638854980469,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 0.4784,
      "step": 385
    },
    {
      "epoch": 0.2773333333333333,
      "grad_norm": 47.460166931152344,
      "learning_rate": 1.1051136363636366e-05,
      "loss": 1.0099,
      "step": 390
    },
    {
      "epoch": 0.2808888888888889,
      "grad_norm": 85.42009735107422,
      "learning_rate": 1.119318181818182e-05,
      "loss": 0.9504,
      "step": 395
    },
    {
      "epoch": 0.28444444444444444,
      "grad_norm": 49.70390701293945,
      "learning_rate": 1.1335227272727274e-05,
      "loss": 1.2118,
      "step": 400
    },
    {
      "epoch": 0.28444444444444444,
      "eval_accuracy": 0.8904,
      "eval_f1": 0.8854515050167224,
      "eval_loss": 0.7876492142677307,
      "eval_precision": 0.9273204903677759,
      "eval_recall": 0.8472,
      "eval_roc_auc": 0.95724816,
      "eval_runtime": 615.7904,
      "eval_samples_per_second": 8.12,
      "eval_steps_per_second": 0.508,
      "step": 400
    },
    {
      "epoch": 0.288,
      "grad_norm": 35.916893005371094,
      "learning_rate": 1.1477272727272729e-05,
      "loss": 0.6784,
      "step": 405
    },
    {
      "epoch": 0.29155555555555557,
      "grad_norm": 57.12773895263672,
      "learning_rate": 1.1619318181818182e-05,
      "loss": 0.4976,
      "step": 410
    },
    {
      "epoch": 0.2951111111111111,
      "grad_norm": 19.974571228027344,
      "learning_rate": 1.1761363636363637e-05,
      "loss": 0.7653,
      "step": 415
    },
    {
      "epoch": 0.2986666666666667,
      "grad_norm": 75.99915313720703,
      "learning_rate": 1.1903409090909093e-05,
      "loss": 0.7383,
      "step": 420
    },
    {
      "epoch": 0.3022222222222222,
      "grad_norm": 53.00996780395508,
      "learning_rate": 1.2045454545454547e-05,
      "loss": 0.8646,
      "step": 425
    },
    {
      "epoch": 0.30577777777777776,
      "grad_norm": 71.48524475097656,
      "learning_rate": 1.2187500000000001e-05,
      "loss": 0.6808,
      "step": 430
    },
    {
      "epoch": 0.30933333333333335,
      "grad_norm": 47.515071868896484,
      "learning_rate": 1.2329545454545455e-05,
      "loss": 0.2662,
      "step": 435
    },
    {
      "epoch": 0.3128888888888889,
      "grad_norm": 77.61316680908203,
      "learning_rate": 1.247159090909091e-05,
      "loss": 0.6732,
      "step": 440
    },
    {
      "epoch": 0.3164444444444444,
      "grad_norm": 40.561092376708984,
      "learning_rate": 1.2613636363636366e-05,
      "loss": 0.69,
      "step": 445
    },
    {
      "epoch": 0.32,
      "grad_norm": 62.28592300415039,
      "learning_rate": 1.275568181818182e-05,
      "loss": 0.4323,
      "step": 450
    },
    {
      "epoch": 0.32355555555555554,
      "grad_norm": 71.55712890625,
      "learning_rate": 1.2897727272727274e-05,
      "loss": 0.6769,
      "step": 455
    },
    {
      "epoch": 0.32711111111111113,
      "grad_norm": 110.97278594970703,
      "learning_rate": 1.3039772727272728e-05,
      "loss": 0.3234,
      "step": 460
    },
    {
      "epoch": 0.33066666666666666,
      "grad_norm": 93.39161682128906,
      "learning_rate": 1.3181818181818183e-05,
      "loss": 0.8402,
      "step": 465
    },
    {
      "epoch": 0.3342222222222222,
      "grad_norm": 59.63267135620117,
      "learning_rate": 1.3323863636363636e-05,
      "loss": 0.741,
      "step": 470
    },
    {
      "epoch": 0.3377777777777778,
      "grad_norm": 46.59782409667969,
      "learning_rate": 1.3465909090909092e-05,
      "loss": 0.5854,
      "step": 475
    },
    {
      "epoch": 0.3413333333333333,
      "grad_norm": 38.55038833618164,
      "learning_rate": 1.3607954545454547e-05,
      "loss": 0.8753,
      "step": 480
    },
    {
      "epoch": 0.3448888888888889,
      "grad_norm": 74.9189453125,
      "learning_rate": 1.375e-05,
      "loss": 0.7566,
      "step": 485
    },
    {
      "epoch": 0.34844444444444445,
      "grad_norm": 89.84039306640625,
      "learning_rate": 1.3892045454545455e-05,
      "loss": 0.7583,
      "step": 490
    },
    {
      "epoch": 0.352,
      "grad_norm": 1.438025712966919,
      "learning_rate": 1.4034090909090909e-05,
      "loss": 0.3369,
      "step": 495
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 36.066959381103516,
      "learning_rate": 1.4176136363636365e-05,
      "loss": 0.4912,
      "step": 500
    },
    {
      "epoch": 0.35555555555555557,
      "eval_accuracy": 0.9056,
      "eval_f1": 0.9075959279561472,
      "eval_loss": 0.5913320183753967,
      "eval_precision": 0.8888036809815951,
      "eval_recall": 0.9272,
      "eval_roc_auc": 0.9691760800000001,
      "eval_runtime": 616.018,
      "eval_samples_per_second": 8.117,
      "eval_steps_per_second": 0.508,
      "step": 500
    },
    {
      "epoch": 0.3591111111111111,
      "grad_norm": 45.04471206665039,
      "learning_rate": 1.431818181818182e-05,
      "loss": 1.0032,
      "step": 505
    },
    {
      "epoch": 0.3626666666666667,
      "grad_norm": 88.18928527832031,
      "learning_rate": 1.4460227272727273e-05,
      "loss": 0.9947,
      "step": 510
    },
    {
      "epoch": 0.3662222222222222,
      "grad_norm": 63.48478698730469,
      "learning_rate": 1.4602272727272728e-05,
      "loss": 0.3904,
      "step": 515
    },
    {
      "epoch": 0.36977777777777776,
      "grad_norm": 35.4589958190918,
      "learning_rate": 1.4744318181818183e-05,
      "loss": 0.733,
      "step": 520
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 101.9940414428711,
      "learning_rate": 1.4886363636363636e-05,
      "loss": 0.4547,
      "step": 525
    },
    {
      "epoch": 0.3768888888888889,
      "grad_norm": 113.47817993164062,
      "learning_rate": 1.5028409090909093e-05,
      "loss": 0.451,
      "step": 530
    },
    {
      "epoch": 0.3804444444444444,
      "grad_norm": 40.45759963989258,
      "learning_rate": 1.5170454545454546e-05,
      "loss": 0.4525,
      "step": 535
    },
    {
      "epoch": 0.384,
      "grad_norm": 33.47982406616211,
      "learning_rate": 1.5312500000000003e-05,
      "loss": 0.2013,
      "step": 540
    },
    {
      "epoch": 0.38755555555555554,
      "grad_norm": 48.709312438964844,
      "learning_rate": 1.5454545454545454e-05,
      "loss": 0.4783,
      "step": 545
    },
    {
      "epoch": 0.39111111111111113,
      "grad_norm": 34.72821807861328,
      "learning_rate": 1.559659090909091e-05,
      "loss": 0.4613,
      "step": 550
    },
    {
      "epoch": 0.39466666666666667,
      "grad_norm": 94.16166687011719,
      "learning_rate": 1.5738636363636364e-05,
      "loss": 0.3061,
      "step": 555
    },
    {
      "epoch": 0.3982222222222222,
      "grad_norm": 27.10784149169922,
      "learning_rate": 1.588068181818182e-05,
      "loss": 0.5869,
      "step": 560
    },
    {
      "epoch": 0.4017777777777778,
      "grad_norm": 48.544612884521484,
      "learning_rate": 1.6022727272727274e-05,
      "loss": 0.5775,
      "step": 565
    },
    {
      "epoch": 0.4053333333333333,
      "grad_norm": 37.41934585571289,
      "learning_rate": 1.616477272727273e-05,
      "loss": 0.4483,
      "step": 570
    },
    {
      "epoch": 0.4088888888888889,
      "grad_norm": 65.66374206542969,
      "learning_rate": 1.6306818181818184e-05,
      "loss": 0.4814,
      "step": 575
    },
    {
      "epoch": 0.41244444444444445,
      "grad_norm": 36.53532028198242,
      "learning_rate": 1.6448863636363635e-05,
      "loss": 0.3653,
      "step": 580
    },
    {
      "epoch": 0.416,
      "grad_norm": 47.90544128417969,
      "learning_rate": 1.6590909090909094e-05,
      "loss": 0.5345,
      "step": 585
    },
    {
      "epoch": 0.41955555555555557,
      "grad_norm": 64.08419036865234,
      "learning_rate": 1.673295454545455e-05,
      "loss": 0.501,
      "step": 590
    },
    {
      "epoch": 0.4231111111111111,
      "grad_norm": 81.6323471069336,
      "learning_rate": 1.6875e-05,
      "loss": 0.5292,
      "step": 595
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 86.4755630493164,
      "learning_rate": 1.7017045454545455e-05,
      "loss": 2.3551,
      "step": 600
    },
    {
      "epoch": 0.4266666666666667,
      "eval_accuracy": 0.8466,
      "eval_f1": 0.8648934296283248,
      "eval_loss": 1.2574251890182495,
      "eval_precision": 0.7727415801070192,
      "eval_recall": 0.982,
      "eval_roc_auc": 0.9654592,
      "eval_runtime": 616.2021,
      "eval_samples_per_second": 8.114,
      "eval_steps_per_second": 0.508,
      "step": 600
    },
    {
      "epoch": 0.43022222222222223,
      "grad_norm": 37.724952697753906,
      "learning_rate": 1.715909090909091e-05,
      "loss": 1.2368,
      "step": 605
    },
    {
      "epoch": 0.43377777777777776,
      "grad_norm": 94.60496520996094,
      "learning_rate": 1.7301136363636365e-05,
      "loss": 0.5294,
      "step": 610
    },
    {
      "epoch": 0.43733333333333335,
      "grad_norm": 19.02716827392578,
      "learning_rate": 1.744318181818182e-05,
      "loss": 0.3537,
      "step": 615
    },
    {
      "epoch": 0.4408888888888889,
      "grad_norm": 31.920976638793945,
      "learning_rate": 1.7585227272727275e-05,
      "loss": 0.5965,
      "step": 620
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 80.11465454101562,
      "learning_rate": 1.772727272727273e-05,
      "loss": 0.4163,
      "step": 625
    },
    {
      "epoch": 0.448,
      "grad_norm": 37.753936767578125,
      "learning_rate": 1.786931818181818e-05,
      "loss": 0.4343,
      "step": 630
    },
    {
      "epoch": 0.45155555555555554,
      "grad_norm": 44.1302375793457,
      "learning_rate": 1.8011363636363636e-05,
      "loss": 0.4025,
      "step": 635
    },
    {
      "epoch": 0.45511111111111113,
      "grad_norm": 72.0762939453125,
      "learning_rate": 1.8153409090909094e-05,
      "loss": 0.5393,
      "step": 640
    },
    {
      "epoch": 0.45866666666666667,
      "grad_norm": 33.718658447265625,
      "learning_rate": 1.8295454545454546e-05,
      "loss": 0.2186,
      "step": 645
    },
    {
      "epoch": 0.4622222222222222,
      "grad_norm": 77.69378662109375,
      "learning_rate": 1.84375e-05,
      "loss": 0.1552,
      "step": 650
    },
    {
      "epoch": 0.4657777777777778,
      "grad_norm": 3.4878509044647217,
      "learning_rate": 1.8579545454545456e-05,
      "loss": 0.1162,
      "step": 655
    },
    {
      "epoch": 0.4693333333333333,
      "grad_norm": 38.242225646972656,
      "learning_rate": 1.872159090909091e-05,
      "loss": 0.2578,
      "step": 660
    },
    {
      "epoch": 0.4728888888888889,
      "grad_norm": 48.352115631103516,
      "learning_rate": 1.8863636363636366e-05,
      "loss": 0.3056,
      "step": 665
    },
    {
      "epoch": 0.47644444444444445,
      "grad_norm": 25.23224449157715,
      "learning_rate": 1.900568181818182e-05,
      "loss": 0.3007,
      "step": 670
    },
    {
      "epoch": 0.48,
      "grad_norm": 51.746009826660156,
      "learning_rate": 1.9147727272727276e-05,
      "loss": 0.3954,
      "step": 675
    },
    {
      "epoch": 0.48355555555555557,
      "grad_norm": 36.31332015991211,
      "learning_rate": 1.9289772727272727e-05,
      "loss": 0.2526,
      "step": 680
    },
    {
      "epoch": 0.4871111111111111,
      "grad_norm": 25.78167152404785,
      "learning_rate": 1.9431818181818182e-05,
      "loss": 0.1673,
      "step": 685
    },
    {
      "epoch": 0.49066666666666664,
      "grad_norm": 84.24769592285156,
      "learning_rate": 1.9573863636363637e-05,
      "loss": 0.3944,
      "step": 690
    },
    {
      "epoch": 0.49422222222222223,
      "grad_norm": 60.2377815246582,
      "learning_rate": 1.9715909090909092e-05,
      "loss": 0.3846,
      "step": 695
    },
    {
      "epoch": 0.49777777777777776,
      "grad_norm": 44.50230026245117,
      "learning_rate": 1.9857954545454547e-05,
      "loss": 0.2162,
      "step": 700
    },
    {
      "epoch": 0.49777777777777776,
      "eval_accuracy": 0.9386,
      "eval_f1": 0.9391717852189418,
      "eval_loss": 0.37042301893234253,
      "eval_precision": 0.9305064782096584,
      "eval_recall": 0.948,
      "eval_roc_auc": 0.9847176799999999,
      "eval_runtime": 617.2455,
      "eval_samples_per_second": 8.101,
      "eval_steps_per_second": 0.507,
      "step": 700
    },
    {
      "epoch": 0.5013333333333333,
      "grad_norm": 47.942405700683594,
      "learning_rate": 2e-05,
      "loss": 0.244,
      "step": 705
    },
    {
      "epoch": 0.5048888888888889,
      "grad_norm": 18.027143478393555,
      "learning_rate": 1.9999969220262722e-05,
      "loss": 0.3099,
      "step": 710
    },
    {
      "epoch": 0.5084444444444445,
      "grad_norm": 60.5213623046875,
      "learning_rate": 1.999987688124037e-05,
      "loss": 0.1894,
      "step": 715
    },
    {
      "epoch": 0.512,
      "grad_norm": 61.53219985961914,
      "learning_rate": 1.9999722983501374e-05,
      "loss": 0.2092,
      "step": 720
    },
    {
      "epoch": 0.5155555555555555,
      "grad_norm": 69.9820556640625,
      "learning_rate": 1.9999507527993122e-05,
      "loss": 0.6554,
      "step": 725
    },
    {
      "epoch": 0.5191111111111111,
      "grad_norm": 21.35717010498047,
      "learning_rate": 1.9999230516041947e-05,
      "loss": 0.2088,
      "step": 730
    },
    {
      "epoch": 0.5226666666666666,
      "grad_norm": 49.09284591674805,
      "learning_rate": 1.9998891949353116e-05,
      "loss": 0.7248,
      "step": 735
    },
    {
      "epoch": 0.5262222222222223,
      "grad_norm": 22.48965072631836,
      "learning_rate": 1.9998491830010835e-05,
      "loss": 0.212,
      "step": 740
    },
    {
      "epoch": 0.5297777777777778,
      "grad_norm": 27.85070037841797,
      "learning_rate": 1.9998030160478214e-05,
      "loss": 0.3457,
      "step": 745
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 75.21947479248047,
      "learning_rate": 1.9997506943597264e-05,
      "loss": 0.8,
      "step": 750
    },
    {
      "epoch": 0.5368888888888889,
      "grad_norm": 24.47939682006836,
      "learning_rate": 1.9996922182588887e-05,
      "loss": 0.2247,
      "step": 755
    },
    {
      "epoch": 0.5404444444444444,
      "grad_norm": 21.85172462463379,
      "learning_rate": 1.9996275881052835e-05,
      "loss": 0.3493,
      "step": 760
    },
    {
      "epoch": 0.544,
      "grad_norm": 55.37650680541992,
      "learning_rate": 1.999556804296771e-05,
      "loss": 0.4554,
      "step": 765
    },
    {
      "epoch": 0.5475555555555556,
      "grad_norm": 37.922061920166016,
      "learning_rate": 1.9994798672690922e-05,
      "loss": 0.3227,
      "step": 770
    },
    {
      "epoch": 0.5511111111111111,
      "grad_norm": 75.07903289794922,
      "learning_rate": 1.9993967774958682e-05,
      "loss": 0.5934,
      "step": 775
    },
    {
      "epoch": 0.5546666666666666,
      "grad_norm": 79.53080749511719,
      "learning_rate": 1.999307535488594e-05,
      "loss": 0.6595,
      "step": 780
    },
    {
      "epoch": 0.5582222222222222,
      "grad_norm": 39.62683868408203,
      "learning_rate": 1.99921214179664e-05,
      "loss": 0.4387,
      "step": 785
    },
    {
      "epoch": 0.5617777777777778,
      "grad_norm": 48.381832122802734,
      "learning_rate": 1.999110597007244e-05,
      "loss": 0.4466,
      "step": 790
    },
    {
      "epoch": 0.5653333333333334,
      "grad_norm": 21.694896697998047,
      "learning_rate": 1.9990029017455102e-05,
      "loss": 0.2343,
      "step": 795
    },
    {
      "epoch": 0.5688888888888889,
      "grad_norm": 86.31519317626953,
      "learning_rate": 1.998889056674406e-05,
      "loss": 0.251,
      "step": 800
    },
    {
      "epoch": 0.5688888888888889,
      "eval_accuracy": 0.9412,
      "eval_f1": 0.9416435093290988,
      "eval_loss": 0.27039268612861633,
      "eval_precision": 0.9345941686367218,
      "eval_recall": 0.9488,
      "eval_roc_auc": 0.98672312,
      "eval_runtime": 617.5118,
      "eval_samples_per_second": 8.097,
      "eval_steps_per_second": 0.507,
      "step": 800
    },
    {
      "epoch": 0.5724444444444444,
      "grad_norm": 16.286462783813477,
      "learning_rate": 1.998769062494755e-05,
      "loss": 0.156,
      "step": 805
    },
    {
      "epoch": 0.576,
      "grad_norm": 35.34084701538086,
      "learning_rate": 1.9986429199452347e-05,
      "loss": 0.658,
      "step": 810
    },
    {
      "epoch": 0.5795555555555556,
      "grad_norm": 15.691337585449219,
      "learning_rate": 1.9985106298023727e-05,
      "loss": 0.226,
      "step": 815
    },
    {
      "epoch": 0.5831111111111111,
      "grad_norm": 18.49640655517578,
      "learning_rate": 1.9983721928805397e-05,
      "loss": 0.2254,
      "step": 820
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 75.99523162841797,
      "learning_rate": 1.9982276100319463e-05,
      "loss": 0.385,
      "step": 825
    },
    {
      "epoch": 0.5902222222222222,
      "grad_norm": 68.4736328125,
      "learning_rate": 1.998076882146637e-05,
      "loss": 0.4024,
      "step": 830
    },
    {
      "epoch": 0.5937777777777777,
      "grad_norm": 17.022554397583008,
      "learning_rate": 1.9979200101524844e-05,
      "loss": 0.1141,
      "step": 835
    },
    {
      "epoch": 0.5973333333333334,
      "grad_norm": 2.1221814155578613,
      "learning_rate": 1.9977569950151848e-05,
      "loss": 0.3746,
      "step": 840
    },
    {
      "epoch": 0.6008888888888889,
      "grad_norm": 23.238235473632812,
      "learning_rate": 1.9975878377382505e-05,
      "loss": 0.188,
      "step": 845
    },
    {
      "epoch": 0.6044444444444445,
      "grad_norm": 57.049739837646484,
      "learning_rate": 1.997412539363005e-05,
      "loss": 0.222,
      "step": 850
    },
    {
      "epoch": 0.608,
      "grad_norm": 49.909141540527344,
      "learning_rate": 1.9972311009685753e-05,
      "loss": 0.3128,
      "step": 855
    },
    {
      "epoch": 0.6115555555555555,
      "grad_norm": 50.07534408569336,
      "learning_rate": 1.997043523671887e-05,
      "loss": 0.3572,
      "step": 860
    },
    {
      "epoch": 0.6151111111111112,
      "grad_norm": 37.229278564453125,
      "learning_rate": 1.9968498086276565e-05,
      "loss": 0.5168,
      "step": 865
    },
    {
      "epoch": 0.6186666666666667,
      "grad_norm": 1.513396978378296,
      "learning_rate": 1.996649957028383e-05,
      "loss": 0.201,
      "step": 870
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 20.987503051757812,
      "learning_rate": 1.9964439701043422e-05,
      "loss": 0.1118,
      "step": 875
    },
    {
      "epoch": 0.6257777777777778,
      "grad_norm": 39.5469856262207,
      "learning_rate": 1.9962318491235795e-05,
      "loss": 0.2608,
      "step": 880
    },
    {
      "epoch": 0.6293333333333333,
      "grad_norm": 11.383951187133789,
      "learning_rate": 1.9960135953918996e-05,
      "loss": 0.2053,
      "step": 885
    },
    {
      "epoch": 0.6328888888888888,
      "grad_norm": 59.172218322753906,
      "learning_rate": 1.995789210252862e-05,
      "loss": 0.1337,
      "step": 890
    },
    {
      "epoch": 0.6364444444444445,
      "grad_norm": 35.58428955078125,
      "learning_rate": 1.9955586950877693e-05,
      "loss": 0.4863,
      "step": 895
    },
    {
      "epoch": 0.64,
      "grad_norm": 55.85548400878906,
      "learning_rate": 1.9953220513156604e-05,
      "loss": 0.2165,
      "step": 900
    },
    {
      "epoch": 0.64,
      "eval_accuracy": 0.941,
      "eval_f1": 0.9426850592578201,
      "eval_loss": 0.2532116770744324,
      "eval_precision": 0.9165092557612391,
      "eval_recall": 0.9704,
      "eval_roc_auc": 0.9905650399999999,
      "eval_runtime": 616.5095,
      "eval_samples_per_second": 8.11,
      "eval_steps_per_second": 0.508,
      "step": 900
    },
    {
      "epoch": 0.6435555555555555,
      "grad_norm": 36.99977493286133,
      "learning_rate": 1.9950792803933024e-05,
      "loss": 0.3784,
      "step": 905
    },
    {
      "epoch": 0.6471111111111111,
      "grad_norm": 25.826858520507812,
      "learning_rate": 1.9948303838151805e-05,
      "loss": 0.1243,
      "step": 910
    },
    {
      "epoch": 0.6506666666666666,
      "grad_norm": 2.9413909912109375,
      "learning_rate": 1.9945753631134884e-05,
      "loss": 0.2043,
      "step": 915
    },
    {
      "epoch": 0.6542222222222223,
      "grad_norm": 38.90449905395508,
      "learning_rate": 1.9943142198581203e-05,
      "loss": 0.3189,
      "step": 920
    },
    {
      "epoch": 0.6577777777777778,
      "grad_norm": 34.86366271972656,
      "learning_rate": 1.9940469556566612e-05,
      "loss": 0.3001,
      "step": 925
    },
    {
      "epoch": 0.6613333333333333,
      "grad_norm": 14.526966094970703,
      "learning_rate": 1.9937735721543742e-05,
      "loss": 0.1169,
      "step": 930
    },
    {
      "epoch": 0.6648888888888889,
      "grad_norm": 5.871160984039307,
      "learning_rate": 1.9934940710341942e-05,
      "loss": 0.0664,
      "step": 935
    },
    {
      "epoch": 0.6684444444444444,
      "grad_norm": 46.10857391357422,
      "learning_rate": 1.993208454016716e-05,
      "loss": 0.1533,
      "step": 940
    },
    {
      "epoch": 0.672,
      "grad_norm": 22.042757034301758,
      "learning_rate": 1.992916722860182e-05,
      "loss": 0.1811,
      "step": 945
    },
    {
      "epoch": 0.6755555555555556,
      "grad_norm": 33.282894134521484,
      "learning_rate": 1.992618879360475e-05,
      "loss": 0.1865,
      "step": 950
    },
    {
      "epoch": 0.6791111111111111,
      "grad_norm": 60.23435592651367,
      "learning_rate": 1.9923149253511028e-05,
      "loss": 0.4264,
      "step": 955
    },
    {
      "epoch": 0.6826666666666666,
      "grad_norm": 38.40011215209961,
      "learning_rate": 1.9920048627031915e-05,
      "loss": 0.0832,
      "step": 960
    },
    {
      "epoch": 0.6862222222222222,
      "grad_norm": 26.662242889404297,
      "learning_rate": 1.991688693325469e-05,
      "loss": 0.2235,
      "step": 965
    },
    {
      "epoch": 0.6897777777777778,
      "grad_norm": 24.531044006347656,
      "learning_rate": 1.9913664191642587e-05,
      "loss": 0.1847,
      "step": 970
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 21.217660903930664,
      "learning_rate": 1.9910380422034627e-05,
      "loss": 0.2042,
      "step": 975
    },
    {
      "epoch": 0.6968888888888889,
      "grad_norm": 3.40928053855896,
      "learning_rate": 1.9907035644645524e-05,
      "loss": 0.1348,
      "step": 980
    },
    {
      "epoch": 0.7004444444444444,
      "grad_norm": 36.54404830932617,
      "learning_rate": 1.9903629880065555e-05,
      "loss": 0.4595,
      "step": 985
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.022319400683045387,
      "learning_rate": 1.9900163149260424e-05,
      "loss": 0.1084,
      "step": 990
    },
    {
      "epoch": 0.7075555555555556,
      "grad_norm": 31.220624923706055,
      "learning_rate": 1.9896635473571145e-05,
      "loss": 0.2212,
      "step": 995
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 24.955896377563477,
      "learning_rate": 1.9893046874713903e-05,
      "loss": 0.0962,
      "step": 1000
    },
    {
      "epoch": 0.7111111111111111,
      "eval_accuracy": 0.9482,
      "eval_f1": 0.9458498850094085,
      "eval_loss": 0.3039567768573761,
      "eval_precision": 0.9908015768725361,
      "eval_recall": 0.9048,
      "eval_roc_auc": 0.98912208,
      "eval_runtime": 616.4774,
      "eval_samples_per_second": 8.111,
      "eval_steps_per_second": 0.508,
      "step": 1000
    }
  ],
  "logging_steps": 5,
  "max_steps": 7035,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.001
      },
      "attributes": {
        "early_stopping_patience_counter": 1
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.87463068598272e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
