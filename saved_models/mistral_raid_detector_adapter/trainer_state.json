{
  "best_global_step": 1600,
  "best_metric": 0.99650456,
  "best_model_checkpoint": "./saved_models/mistral_raid_detector_adapter/checkpoint-1500",
  "epoch": 1.3505777777777777,
  "eval_steps": 100,
  "global_step": 1900,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0035555555555555557,
      "grad_norm": 71.04328918457031,
      "learning_rate": 1.1363636363636364e-07,
      "loss": 3.199,
      "step": 5
    },
    {
      "epoch": 0.0071111111111111115,
      "grad_norm": 93.5253677368164,
      "learning_rate": 2.556818181818182e-07,
      "loss": 4.053,
      "step": 10
    },
    {
      "epoch": 0.010666666666666666,
      "grad_norm": 88.8437728881836,
      "learning_rate": 3.9772727272727276e-07,
      "loss": 3.4953,
      "step": 15
    },
    {
      "epoch": 0.014222222222222223,
      "grad_norm": 77.8512191772461,
      "learning_rate": 5.397727272727273e-07,
      "loss": 3.4161,
      "step": 20
    },
    {
      "epoch": 0.017777777777777778,
      "grad_norm": 83.5049057006836,
      "learning_rate": 6.818181818181818e-07,
      "loss": 3.3839,
      "step": 25
    },
    {
      "epoch": 0.021333333333333333,
      "grad_norm": 107.94293975830078,
      "learning_rate": 8.238636363636364e-07,
      "loss": 3.2606,
      "step": 30
    },
    {
      "epoch": 0.024888888888888887,
      "grad_norm": 102.4188003540039,
      "learning_rate": 9.65909090909091e-07,
      "loss": 3.259,
      "step": 35
    },
    {
      "epoch": 0.028444444444444446,
      "grad_norm": 86.81859588623047,
      "learning_rate": 1.1079545454545456e-06,
      "loss": 3.7254,
      "step": 40
    },
    {
      "epoch": 0.032,
      "grad_norm": 79.50184631347656,
      "learning_rate": 1.25e-06,
      "loss": 3.6664,
      "step": 45
    },
    {
      "epoch": 0.035555555555555556,
      "grad_norm": 88.2386245727539,
      "learning_rate": 1.3920454545454546e-06,
      "loss": 3.1795,
      "step": 50
    },
    {
      "epoch": 0.03911111111111111,
      "grad_norm": 80.6746826171875,
      "learning_rate": 1.5340909090909093e-06,
      "loss": 3.6724,
      "step": 55
    },
    {
      "epoch": 0.042666666666666665,
      "grad_norm": 107.36078643798828,
      "learning_rate": 1.6761363636363636e-06,
      "loss": 3.5076,
      "step": 60
    },
    {
      "epoch": 0.04622222222222222,
      "grad_norm": 63.777278900146484,
      "learning_rate": 1.8181818181818183e-06,
      "loss": 3.4842,
      "step": 65
    },
    {
      "epoch": 0.049777777777777775,
      "grad_norm": 75.39788055419922,
      "learning_rate": 1.9602272727272728e-06,
      "loss": 3.3059,
      "step": 70
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 94.22563934326172,
      "learning_rate": 2.1022727272727277e-06,
      "loss": 3.0093,
      "step": 75
    },
    {
      "epoch": 0.05688888888888889,
      "grad_norm": 99.65691375732422,
      "learning_rate": 2.2443181818181818e-06,
      "loss": 2.9073,
      "step": 80
    },
    {
      "epoch": 0.060444444444444446,
      "grad_norm": 92.19189453125,
      "learning_rate": 2.3863636363636367e-06,
      "loss": 3.5358,
      "step": 85
    },
    {
      "epoch": 0.064,
      "grad_norm": 73.14012908935547,
      "learning_rate": 2.528409090909091e-06,
      "loss": 3.9857,
      "step": 90
    },
    {
      "epoch": 0.06755555555555555,
      "grad_norm": 81.0314712524414,
      "learning_rate": 2.6704545454545457e-06,
      "loss": 3.5816,
      "step": 95
    },
    {
      "epoch": 0.07111111111111111,
      "grad_norm": 76.77008056640625,
      "learning_rate": 2.8125e-06,
      "loss": 3.1228,
      "step": 100
    },
    {
      "epoch": 0.07111111111111111,
      "eval_accuracy": 0.5416,
      "eval_f1": 0.5466772151898733,
      "eval_loss": 3.3244566917419434,
      "eval_precision": 0.5406885758998435,
      "eval_recall": 0.5528,
      "eval_roc_auc": 0.55644768,
      "eval_runtime": 617.4876,
      "eval_samples_per_second": 8.097,
      "eval_steps_per_second": 0.507,
      "step": 100
    },
    {
      "epoch": 0.07466666666666667,
      "grad_norm": 88.65370178222656,
      "learning_rate": 2.954545454545455e-06,
      "loss": 3.8884,
      "step": 105
    },
    {
      "epoch": 0.07822222222222222,
      "grad_norm": 111.03863525390625,
      "learning_rate": 3.096590909090909e-06,
      "loss": 3.6717,
      "step": 110
    },
    {
      "epoch": 0.08177777777777778,
      "grad_norm": 74.07740783691406,
      "learning_rate": 3.2386363636363637e-06,
      "loss": 3.3696,
      "step": 115
    },
    {
      "epoch": 0.08533333333333333,
      "grad_norm": 62.01462173461914,
      "learning_rate": 3.3806818181818186e-06,
      "loss": 3.09,
      "step": 120
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 60.25017166137695,
      "learning_rate": 3.522727272727273e-06,
      "loss": 2.5665,
      "step": 125
    },
    {
      "epoch": 0.09244444444444444,
      "grad_norm": 83.81108093261719,
      "learning_rate": 3.6647727272727276e-06,
      "loss": 2.8816,
      "step": 130
    },
    {
      "epoch": 0.096,
      "grad_norm": 78.8825454711914,
      "learning_rate": 3.806818181818182e-06,
      "loss": 2.6929,
      "step": 135
    },
    {
      "epoch": 0.09955555555555555,
      "grad_norm": 58.09162139892578,
      "learning_rate": 3.9488636363636366e-06,
      "loss": 2.9076,
      "step": 140
    },
    {
      "epoch": 0.10311111111111111,
      "grad_norm": 71.34232330322266,
      "learning_rate": 4.0909090909090915e-06,
      "loss": 2.8492,
      "step": 145
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 74.09046173095703,
      "learning_rate": 4.2329545454545455e-06,
      "loss": 2.5419,
      "step": 150
    },
    {
      "epoch": 0.11022222222222222,
      "grad_norm": 63.935787200927734,
      "learning_rate": 4.3750000000000005e-06,
      "loss": 2.072,
      "step": 155
    },
    {
      "epoch": 0.11377777777777778,
      "grad_norm": 79.86321258544922,
      "learning_rate": 4.517045454545455e-06,
      "loss": 2.7848,
      "step": 160
    },
    {
      "epoch": 0.11733333333333333,
      "grad_norm": 77.87474822998047,
      "learning_rate": 4.6590909090909095e-06,
      "loss": 2.0533,
      "step": 165
    },
    {
      "epoch": 0.12088888888888889,
      "grad_norm": 90.08426666259766,
      "learning_rate": 4.8011363636363635e-06,
      "loss": 2.4981,
      "step": 170
    },
    {
      "epoch": 0.12444444444444444,
      "grad_norm": 64.60723876953125,
      "learning_rate": 4.9431818181818184e-06,
      "loss": 2.1348,
      "step": 175
    },
    {
      "epoch": 0.128,
      "grad_norm": 63.45016860961914,
      "learning_rate": 5.085227272727273e-06,
      "loss": 1.2775,
      "step": 180
    },
    {
      "epoch": 0.13155555555555556,
      "grad_norm": 56.58731460571289,
      "learning_rate": 5.2272727272727274e-06,
      "loss": 1.8711,
      "step": 185
    },
    {
      "epoch": 0.1351111111111111,
      "grad_norm": 55.79026794433594,
      "learning_rate": 5.369318181818182e-06,
      "loss": 1.6205,
      "step": 190
    },
    {
      "epoch": 0.13866666666666666,
      "grad_norm": 64.19409942626953,
      "learning_rate": 5.511363636363637e-06,
      "loss": 1.8185,
      "step": 195
    },
    {
      "epoch": 0.14222222222222222,
      "grad_norm": 68.09229278564453,
      "learning_rate": 5.653409090909091e-06,
      "loss": 1.9918,
      "step": 200
    },
    {
      "epoch": 0.14222222222222222,
      "eval_accuracy": 0.7336,
      "eval_f1": 0.7356093687971418,
      "eval_loss": 1.7695804834365845,
      "eval_precision": 0.7301024428684003,
      "eval_recall": 0.7412,
      "eval_roc_auc": 0.8016439200000001,
      "eval_runtime": 615.1134,
      "eval_samples_per_second": 8.129,
      "eval_steps_per_second": 0.509,
      "step": 200
    },
    {
      "epoch": 0.14577777777777778,
      "grad_norm": 50.9853515625,
      "learning_rate": 5.795454545454546e-06,
      "loss": 1.8334,
      "step": 205
    },
    {
      "epoch": 0.14933333333333335,
      "grad_norm": 54.55915451049805,
      "learning_rate": 5.9375e-06,
      "loss": 1.3688,
      "step": 210
    },
    {
      "epoch": 0.15288888888888888,
      "grad_norm": 53.107540130615234,
      "learning_rate": 6.079545454545454e-06,
      "loss": 2.0339,
      "step": 215
    },
    {
      "epoch": 0.15644444444444444,
      "grad_norm": 87.46237182617188,
      "learning_rate": 6.22159090909091e-06,
      "loss": 1.468,
      "step": 220
    },
    {
      "epoch": 0.16,
      "grad_norm": 76.26721954345703,
      "learning_rate": 6.363636363636364e-06,
      "loss": 1.0681,
      "step": 225
    },
    {
      "epoch": 0.16355555555555557,
      "grad_norm": 47.2247314453125,
      "learning_rate": 6.505681818181818e-06,
      "loss": 1.3088,
      "step": 230
    },
    {
      "epoch": 0.1671111111111111,
      "grad_norm": 72.8374252319336,
      "learning_rate": 6.647727272727273e-06,
      "loss": 1.3234,
      "step": 235
    },
    {
      "epoch": 0.17066666666666666,
      "grad_norm": 93.10860443115234,
      "learning_rate": 6.789772727272727e-06,
      "loss": 1.1386,
      "step": 240
    },
    {
      "epoch": 0.17422222222222222,
      "grad_norm": 70.82707977294922,
      "learning_rate": 6.931818181818183e-06,
      "loss": 1.5705,
      "step": 245
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 59.78190231323242,
      "learning_rate": 7.073863636363637e-06,
      "loss": 1.6872,
      "step": 250
    },
    {
      "epoch": 0.18133333333333335,
      "grad_norm": 56.15513610839844,
      "learning_rate": 7.215909090909091e-06,
      "loss": 1.356,
      "step": 255
    },
    {
      "epoch": 0.18488888888888888,
      "grad_norm": 52.503326416015625,
      "learning_rate": 7.357954545454546e-06,
      "loss": 1.1186,
      "step": 260
    },
    {
      "epoch": 0.18844444444444444,
      "grad_norm": 86.41956329345703,
      "learning_rate": 7.500000000000001e-06,
      "loss": 1.2311,
      "step": 265
    },
    {
      "epoch": 0.192,
      "grad_norm": 67.4327163696289,
      "learning_rate": 7.642045454545454e-06,
      "loss": 1.3418,
      "step": 270
    },
    {
      "epoch": 0.19555555555555557,
      "grad_norm": 44.249473571777344,
      "learning_rate": 7.784090909090911e-06,
      "loss": 1.0673,
      "step": 275
    },
    {
      "epoch": 0.1991111111111111,
      "grad_norm": 55.277565002441406,
      "learning_rate": 7.926136363636364e-06,
      "loss": 1.331,
      "step": 280
    },
    {
      "epoch": 0.20266666666666666,
      "grad_norm": 102.40503692626953,
      "learning_rate": 8.068181818181819e-06,
      "loss": 1.4487,
      "step": 285
    },
    {
      "epoch": 0.20622222222222222,
      "grad_norm": 95.21125793457031,
      "learning_rate": 8.210227272727274e-06,
      "loss": 1.3679,
      "step": 290
    },
    {
      "epoch": 0.20977777777777779,
      "grad_norm": 40.16487503051758,
      "learning_rate": 8.352272727272727e-06,
      "loss": 0.9609,
      "step": 295
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 62.939735412597656,
      "learning_rate": 8.494318181818184e-06,
      "loss": 1.2111,
      "step": 300
    },
    {
      "epoch": 0.21333333333333335,
      "eval_accuracy": 0.8368,
      "eval_f1": 0.8391801340165549,
      "eval_loss": 1.0403927564620972,
      "eval_precision": 0.8271173271173271,
      "eval_recall": 0.8516,
      "eval_roc_auc": 0.9212188000000001,
      "eval_runtime": 615.6218,
      "eval_samples_per_second": 8.122,
      "eval_steps_per_second": 0.508,
      "step": 300
    },
    {
      "epoch": 0.21688888888888888,
      "grad_norm": 66.02793884277344,
      "learning_rate": 8.636363636363637e-06,
      "loss": 1.0098,
      "step": 305
    },
    {
      "epoch": 0.22044444444444444,
      "grad_norm": 63.184356689453125,
      "learning_rate": 8.778409090909092e-06,
      "loss": 0.8753,
      "step": 310
    },
    {
      "epoch": 0.224,
      "grad_norm": 48.896644592285156,
      "learning_rate": 8.920454545454547e-06,
      "loss": 1.3269,
      "step": 315
    },
    {
      "epoch": 0.22755555555555557,
      "grad_norm": 62.976524353027344,
      "learning_rate": 9.0625e-06,
      "loss": 1.0106,
      "step": 320
    },
    {
      "epoch": 0.2311111111111111,
      "grad_norm": 48.09809494018555,
      "learning_rate": 9.204545454545455e-06,
      "loss": 0.9496,
      "step": 325
    },
    {
      "epoch": 0.23466666666666666,
      "grad_norm": 88.64533233642578,
      "learning_rate": 9.34659090909091e-06,
      "loss": 0.9618,
      "step": 330
    },
    {
      "epoch": 0.23822222222222222,
      "grad_norm": 40.25056838989258,
      "learning_rate": 9.488636363636365e-06,
      "loss": 0.75,
      "step": 335
    },
    {
      "epoch": 0.24177777777777779,
      "grad_norm": 58.73966979980469,
      "learning_rate": 9.630681818181818e-06,
      "loss": 0.8281,
      "step": 340
    },
    {
      "epoch": 0.24533333333333332,
      "grad_norm": 54.121482849121094,
      "learning_rate": 9.772727272727273e-06,
      "loss": 0.4321,
      "step": 345
    },
    {
      "epoch": 0.24888888888888888,
      "grad_norm": 49.83610916137695,
      "learning_rate": 9.914772727272728e-06,
      "loss": 1.0093,
      "step": 350
    },
    {
      "epoch": 0.25244444444444447,
      "grad_norm": 59.908878326416016,
      "learning_rate": 1.0056818181818183e-05,
      "loss": 0.7023,
      "step": 355
    },
    {
      "epoch": 0.256,
      "grad_norm": 55.440486907958984,
      "learning_rate": 1.0198863636363636e-05,
      "loss": 0.7911,
      "step": 360
    },
    {
      "epoch": 0.25955555555555554,
      "grad_norm": 20.477806091308594,
      "learning_rate": 1.0340909090909093e-05,
      "loss": 0.618,
      "step": 365
    },
    {
      "epoch": 0.26311111111111113,
      "grad_norm": 81.88351440429688,
      "learning_rate": 1.0482954545454548e-05,
      "loss": 0.9571,
      "step": 370
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 101.2985610961914,
      "learning_rate": 1.0625e-05,
      "loss": 0.5872,
      "step": 375
    },
    {
      "epoch": 0.2702222222222222,
      "grad_norm": 56.29861068725586,
      "learning_rate": 1.0767045454545456e-05,
      "loss": 0.6548,
      "step": 380
    },
    {
      "epoch": 0.2737777777777778,
      "grad_norm": 43.12638854980469,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 0.4784,
      "step": 385
    },
    {
      "epoch": 0.2773333333333333,
      "grad_norm": 47.460166931152344,
      "learning_rate": 1.1051136363636366e-05,
      "loss": 1.0099,
      "step": 390
    },
    {
      "epoch": 0.2808888888888889,
      "grad_norm": 85.42009735107422,
      "learning_rate": 1.119318181818182e-05,
      "loss": 0.9504,
      "step": 395
    },
    {
      "epoch": 0.28444444444444444,
      "grad_norm": 49.70390701293945,
      "learning_rate": 1.1335227272727274e-05,
      "loss": 1.2118,
      "step": 400
    },
    {
      "epoch": 0.28444444444444444,
      "eval_accuracy": 0.8904,
      "eval_f1": 0.8854515050167224,
      "eval_loss": 0.7876492142677307,
      "eval_precision": 0.9273204903677759,
      "eval_recall": 0.8472,
      "eval_roc_auc": 0.95724816,
      "eval_runtime": 615.7904,
      "eval_samples_per_second": 8.12,
      "eval_steps_per_second": 0.508,
      "step": 400
    },
    {
      "epoch": 0.288,
      "grad_norm": 35.916893005371094,
      "learning_rate": 1.1477272727272729e-05,
      "loss": 0.6784,
      "step": 405
    },
    {
      "epoch": 0.29155555555555557,
      "grad_norm": 57.12773895263672,
      "learning_rate": 1.1619318181818182e-05,
      "loss": 0.4976,
      "step": 410
    },
    {
      "epoch": 0.2951111111111111,
      "grad_norm": 19.974571228027344,
      "learning_rate": 1.1761363636363637e-05,
      "loss": 0.7653,
      "step": 415
    },
    {
      "epoch": 0.2986666666666667,
      "grad_norm": 75.99915313720703,
      "learning_rate": 1.1903409090909093e-05,
      "loss": 0.7383,
      "step": 420
    },
    {
      "epoch": 0.3022222222222222,
      "grad_norm": 53.00996780395508,
      "learning_rate": 1.2045454545454547e-05,
      "loss": 0.8646,
      "step": 425
    },
    {
      "epoch": 0.30577777777777776,
      "grad_norm": 71.48524475097656,
      "learning_rate": 1.2187500000000001e-05,
      "loss": 0.6808,
      "step": 430
    },
    {
      "epoch": 0.30933333333333335,
      "grad_norm": 47.515071868896484,
      "learning_rate": 1.2329545454545455e-05,
      "loss": 0.2662,
      "step": 435
    },
    {
      "epoch": 0.3128888888888889,
      "grad_norm": 77.61316680908203,
      "learning_rate": 1.247159090909091e-05,
      "loss": 0.6732,
      "step": 440
    },
    {
      "epoch": 0.3164444444444444,
      "grad_norm": 40.561092376708984,
      "learning_rate": 1.2613636363636366e-05,
      "loss": 0.69,
      "step": 445
    },
    {
      "epoch": 0.32,
      "grad_norm": 62.28592300415039,
      "learning_rate": 1.275568181818182e-05,
      "loss": 0.4323,
      "step": 450
    },
    {
      "epoch": 0.32355555555555554,
      "grad_norm": 71.55712890625,
      "learning_rate": 1.2897727272727274e-05,
      "loss": 0.6769,
      "step": 455
    },
    {
      "epoch": 0.32711111111111113,
      "grad_norm": 110.97278594970703,
      "learning_rate": 1.3039772727272728e-05,
      "loss": 0.3234,
      "step": 460
    },
    {
      "epoch": 0.33066666666666666,
      "grad_norm": 93.39161682128906,
      "learning_rate": 1.3181818181818183e-05,
      "loss": 0.8402,
      "step": 465
    },
    {
      "epoch": 0.3342222222222222,
      "grad_norm": 59.63267135620117,
      "learning_rate": 1.3323863636363636e-05,
      "loss": 0.741,
      "step": 470
    },
    {
      "epoch": 0.3377777777777778,
      "grad_norm": 46.59782409667969,
      "learning_rate": 1.3465909090909092e-05,
      "loss": 0.5854,
      "step": 475
    },
    {
      "epoch": 0.3413333333333333,
      "grad_norm": 38.55038833618164,
      "learning_rate": 1.3607954545454547e-05,
      "loss": 0.8753,
      "step": 480
    },
    {
      "epoch": 0.3448888888888889,
      "grad_norm": 74.9189453125,
      "learning_rate": 1.375e-05,
      "loss": 0.7566,
      "step": 485
    },
    {
      "epoch": 0.34844444444444445,
      "grad_norm": 89.84039306640625,
      "learning_rate": 1.3892045454545455e-05,
      "loss": 0.7583,
      "step": 490
    },
    {
      "epoch": 0.352,
      "grad_norm": 1.438025712966919,
      "learning_rate": 1.4034090909090909e-05,
      "loss": 0.3369,
      "step": 495
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 36.066959381103516,
      "learning_rate": 1.4176136363636365e-05,
      "loss": 0.4912,
      "step": 500
    },
    {
      "epoch": 0.35555555555555557,
      "eval_accuracy": 0.9056,
      "eval_f1": 0.9075959279561472,
      "eval_loss": 0.5913320183753967,
      "eval_precision": 0.8888036809815951,
      "eval_recall": 0.9272,
      "eval_roc_auc": 0.9691760800000001,
      "eval_runtime": 616.018,
      "eval_samples_per_second": 8.117,
      "eval_steps_per_second": 0.508,
      "step": 500
    },
    {
      "epoch": 0.3591111111111111,
      "grad_norm": 45.04471206665039,
      "learning_rate": 1.431818181818182e-05,
      "loss": 1.0032,
      "step": 505
    },
    {
      "epoch": 0.3626666666666667,
      "grad_norm": 88.18928527832031,
      "learning_rate": 1.4460227272727273e-05,
      "loss": 0.9947,
      "step": 510
    },
    {
      "epoch": 0.3662222222222222,
      "grad_norm": 63.48478698730469,
      "learning_rate": 1.4602272727272728e-05,
      "loss": 0.3904,
      "step": 515
    },
    {
      "epoch": 0.36977777777777776,
      "grad_norm": 35.4589958190918,
      "learning_rate": 1.4744318181818183e-05,
      "loss": 0.733,
      "step": 520
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 101.9940414428711,
      "learning_rate": 1.4886363636363636e-05,
      "loss": 0.4547,
      "step": 525
    },
    {
      "epoch": 0.3768888888888889,
      "grad_norm": 113.47817993164062,
      "learning_rate": 1.5028409090909093e-05,
      "loss": 0.451,
      "step": 530
    },
    {
      "epoch": 0.3804444444444444,
      "grad_norm": 40.45759963989258,
      "learning_rate": 1.5170454545454546e-05,
      "loss": 0.4525,
      "step": 535
    },
    {
      "epoch": 0.384,
      "grad_norm": 33.47982406616211,
      "learning_rate": 1.5312500000000003e-05,
      "loss": 0.2013,
      "step": 540
    },
    {
      "epoch": 0.38755555555555554,
      "grad_norm": 48.709312438964844,
      "learning_rate": 1.5454545454545454e-05,
      "loss": 0.4783,
      "step": 545
    },
    {
      "epoch": 0.39111111111111113,
      "grad_norm": 34.72821807861328,
      "learning_rate": 1.559659090909091e-05,
      "loss": 0.4613,
      "step": 550
    },
    {
      "epoch": 0.39466666666666667,
      "grad_norm": 94.16166687011719,
      "learning_rate": 1.5738636363636364e-05,
      "loss": 0.3061,
      "step": 555
    },
    {
      "epoch": 0.3982222222222222,
      "grad_norm": 27.10784149169922,
      "learning_rate": 1.588068181818182e-05,
      "loss": 0.5869,
      "step": 560
    },
    {
      "epoch": 0.4017777777777778,
      "grad_norm": 48.544612884521484,
      "learning_rate": 1.6022727272727274e-05,
      "loss": 0.5775,
      "step": 565
    },
    {
      "epoch": 0.4053333333333333,
      "grad_norm": 37.41934585571289,
      "learning_rate": 1.616477272727273e-05,
      "loss": 0.4483,
      "step": 570
    },
    {
      "epoch": 0.4088888888888889,
      "grad_norm": 65.66374206542969,
      "learning_rate": 1.6306818181818184e-05,
      "loss": 0.4814,
      "step": 575
    },
    {
      "epoch": 0.41244444444444445,
      "grad_norm": 36.53532028198242,
      "learning_rate": 1.6448863636363635e-05,
      "loss": 0.3653,
      "step": 580
    },
    {
      "epoch": 0.416,
      "grad_norm": 47.90544128417969,
      "learning_rate": 1.6590909090909094e-05,
      "loss": 0.5345,
      "step": 585
    },
    {
      "epoch": 0.41955555555555557,
      "grad_norm": 64.08419036865234,
      "learning_rate": 1.673295454545455e-05,
      "loss": 0.501,
      "step": 590
    },
    {
      "epoch": 0.4231111111111111,
      "grad_norm": 81.6323471069336,
      "learning_rate": 1.6875e-05,
      "loss": 0.5292,
      "step": 595
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 86.4755630493164,
      "learning_rate": 1.7017045454545455e-05,
      "loss": 2.3551,
      "step": 600
    },
    {
      "epoch": 0.4266666666666667,
      "eval_accuracy": 0.8466,
      "eval_f1": 0.8648934296283248,
      "eval_loss": 1.2574251890182495,
      "eval_precision": 0.7727415801070192,
      "eval_recall": 0.982,
      "eval_roc_auc": 0.9654592,
      "eval_runtime": 616.2021,
      "eval_samples_per_second": 8.114,
      "eval_steps_per_second": 0.508,
      "step": 600
    },
    {
      "epoch": 0.43022222222222223,
      "grad_norm": 37.724952697753906,
      "learning_rate": 1.715909090909091e-05,
      "loss": 1.2368,
      "step": 605
    },
    {
      "epoch": 0.43377777777777776,
      "grad_norm": 94.60496520996094,
      "learning_rate": 1.7301136363636365e-05,
      "loss": 0.5294,
      "step": 610
    },
    {
      "epoch": 0.43733333333333335,
      "grad_norm": 19.02716827392578,
      "learning_rate": 1.744318181818182e-05,
      "loss": 0.3537,
      "step": 615
    },
    {
      "epoch": 0.4408888888888889,
      "grad_norm": 31.920976638793945,
      "learning_rate": 1.7585227272727275e-05,
      "loss": 0.5965,
      "step": 620
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 80.11465454101562,
      "learning_rate": 1.772727272727273e-05,
      "loss": 0.4163,
      "step": 625
    },
    {
      "epoch": 0.448,
      "grad_norm": 37.753936767578125,
      "learning_rate": 1.786931818181818e-05,
      "loss": 0.4343,
      "step": 630
    },
    {
      "epoch": 0.45155555555555554,
      "grad_norm": 44.1302375793457,
      "learning_rate": 1.8011363636363636e-05,
      "loss": 0.4025,
      "step": 635
    },
    {
      "epoch": 0.45511111111111113,
      "grad_norm": 72.0762939453125,
      "learning_rate": 1.8153409090909094e-05,
      "loss": 0.5393,
      "step": 640
    },
    {
      "epoch": 0.45866666666666667,
      "grad_norm": 33.718658447265625,
      "learning_rate": 1.8295454545454546e-05,
      "loss": 0.2186,
      "step": 645
    },
    {
      "epoch": 0.4622222222222222,
      "grad_norm": 77.69378662109375,
      "learning_rate": 1.84375e-05,
      "loss": 0.1552,
      "step": 650
    },
    {
      "epoch": 0.4657777777777778,
      "grad_norm": 3.4878509044647217,
      "learning_rate": 1.8579545454545456e-05,
      "loss": 0.1162,
      "step": 655
    },
    {
      "epoch": 0.4693333333333333,
      "grad_norm": 38.242225646972656,
      "learning_rate": 1.872159090909091e-05,
      "loss": 0.2578,
      "step": 660
    },
    {
      "epoch": 0.4728888888888889,
      "grad_norm": 48.352115631103516,
      "learning_rate": 1.8863636363636366e-05,
      "loss": 0.3056,
      "step": 665
    },
    {
      "epoch": 0.47644444444444445,
      "grad_norm": 25.23224449157715,
      "learning_rate": 1.900568181818182e-05,
      "loss": 0.3007,
      "step": 670
    },
    {
      "epoch": 0.48,
      "grad_norm": 51.746009826660156,
      "learning_rate": 1.9147727272727276e-05,
      "loss": 0.3954,
      "step": 675
    },
    {
      "epoch": 0.48355555555555557,
      "grad_norm": 36.31332015991211,
      "learning_rate": 1.9289772727272727e-05,
      "loss": 0.2526,
      "step": 680
    },
    {
      "epoch": 0.4871111111111111,
      "grad_norm": 25.78167152404785,
      "learning_rate": 1.9431818181818182e-05,
      "loss": 0.1673,
      "step": 685
    },
    {
      "epoch": 0.49066666666666664,
      "grad_norm": 84.24769592285156,
      "learning_rate": 1.9573863636363637e-05,
      "loss": 0.3944,
      "step": 690
    },
    {
      "epoch": 0.49422222222222223,
      "grad_norm": 60.2377815246582,
      "learning_rate": 1.9715909090909092e-05,
      "loss": 0.3846,
      "step": 695
    },
    {
      "epoch": 0.49777777777777776,
      "grad_norm": 44.50230026245117,
      "learning_rate": 1.9857954545454547e-05,
      "loss": 0.2162,
      "step": 700
    },
    {
      "epoch": 0.49777777777777776,
      "eval_accuracy": 0.9386,
      "eval_f1": 0.9391717852189418,
      "eval_loss": 0.37042301893234253,
      "eval_precision": 0.9305064782096584,
      "eval_recall": 0.948,
      "eval_roc_auc": 0.9847176799999999,
      "eval_runtime": 617.2455,
      "eval_samples_per_second": 8.101,
      "eval_steps_per_second": 0.507,
      "step": 700
    },
    {
      "epoch": 0.5013333333333333,
      "grad_norm": 47.942405700683594,
      "learning_rate": 2e-05,
      "loss": 0.244,
      "step": 705
    },
    {
      "epoch": 0.5048888888888889,
      "grad_norm": 18.027143478393555,
      "learning_rate": 1.9999969220262722e-05,
      "loss": 0.3099,
      "step": 710
    },
    {
      "epoch": 0.5084444444444445,
      "grad_norm": 60.5213623046875,
      "learning_rate": 1.999987688124037e-05,
      "loss": 0.1894,
      "step": 715
    },
    {
      "epoch": 0.512,
      "grad_norm": 61.53219985961914,
      "learning_rate": 1.9999722983501374e-05,
      "loss": 0.2092,
      "step": 720
    },
    {
      "epoch": 0.5155555555555555,
      "grad_norm": 69.9820556640625,
      "learning_rate": 1.9999507527993122e-05,
      "loss": 0.6554,
      "step": 725
    },
    {
      "epoch": 0.5191111111111111,
      "grad_norm": 21.35717010498047,
      "learning_rate": 1.9999230516041947e-05,
      "loss": 0.2088,
      "step": 730
    },
    {
      "epoch": 0.5226666666666666,
      "grad_norm": 49.09284591674805,
      "learning_rate": 1.9998891949353116e-05,
      "loss": 0.7248,
      "step": 735
    },
    {
      "epoch": 0.5262222222222223,
      "grad_norm": 22.48965072631836,
      "learning_rate": 1.9998491830010835e-05,
      "loss": 0.212,
      "step": 740
    },
    {
      "epoch": 0.5297777777777778,
      "grad_norm": 27.85070037841797,
      "learning_rate": 1.9998030160478214e-05,
      "loss": 0.3457,
      "step": 745
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 75.21947479248047,
      "learning_rate": 1.9997506943597264e-05,
      "loss": 0.8,
      "step": 750
    },
    {
      "epoch": 0.5368888888888889,
      "grad_norm": 24.47939682006836,
      "learning_rate": 1.9996922182588887e-05,
      "loss": 0.2247,
      "step": 755
    },
    {
      "epoch": 0.5404444444444444,
      "grad_norm": 21.85172462463379,
      "learning_rate": 1.9996275881052835e-05,
      "loss": 0.3493,
      "step": 760
    },
    {
      "epoch": 0.544,
      "grad_norm": 55.37650680541992,
      "learning_rate": 1.999556804296771e-05,
      "loss": 0.4554,
      "step": 765
    },
    {
      "epoch": 0.5475555555555556,
      "grad_norm": 37.922061920166016,
      "learning_rate": 1.9994798672690922e-05,
      "loss": 0.3227,
      "step": 770
    },
    {
      "epoch": 0.5511111111111111,
      "grad_norm": 75.07903289794922,
      "learning_rate": 1.9993967774958682e-05,
      "loss": 0.5934,
      "step": 775
    },
    {
      "epoch": 0.5546666666666666,
      "grad_norm": 79.53080749511719,
      "learning_rate": 1.999307535488594e-05,
      "loss": 0.6595,
      "step": 780
    },
    {
      "epoch": 0.5582222222222222,
      "grad_norm": 39.62683868408203,
      "learning_rate": 1.99921214179664e-05,
      "loss": 0.4387,
      "step": 785
    },
    {
      "epoch": 0.5617777777777778,
      "grad_norm": 48.381832122802734,
      "learning_rate": 1.999110597007244e-05,
      "loss": 0.4466,
      "step": 790
    },
    {
      "epoch": 0.5653333333333334,
      "grad_norm": 21.694896697998047,
      "learning_rate": 1.9990029017455102e-05,
      "loss": 0.2343,
      "step": 795
    },
    {
      "epoch": 0.5688888888888889,
      "grad_norm": 86.31519317626953,
      "learning_rate": 1.998889056674406e-05,
      "loss": 0.251,
      "step": 800
    },
    {
      "epoch": 0.5688888888888889,
      "eval_accuracy": 0.9412,
      "eval_f1": 0.9416435093290988,
      "eval_loss": 0.27039268612861633,
      "eval_precision": 0.9345941686367218,
      "eval_recall": 0.9488,
      "eval_roc_auc": 0.98672312,
      "eval_runtime": 617.5118,
      "eval_samples_per_second": 8.097,
      "eval_steps_per_second": 0.507,
      "step": 800
    },
    {
      "epoch": 0.5724444444444444,
      "grad_norm": 16.286462783813477,
      "learning_rate": 1.998769062494755e-05,
      "loss": 0.156,
      "step": 805
    },
    {
      "epoch": 0.576,
      "grad_norm": 35.34084701538086,
      "learning_rate": 1.9986429199452347e-05,
      "loss": 0.658,
      "step": 810
    },
    {
      "epoch": 0.5795555555555556,
      "grad_norm": 15.691337585449219,
      "learning_rate": 1.9985106298023727e-05,
      "loss": 0.226,
      "step": 815
    },
    {
      "epoch": 0.5831111111111111,
      "grad_norm": 18.49640655517578,
      "learning_rate": 1.9983721928805397e-05,
      "loss": 0.2254,
      "step": 820
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 75.99523162841797,
      "learning_rate": 1.9982276100319463e-05,
      "loss": 0.385,
      "step": 825
    },
    {
      "epoch": 0.5902222222222222,
      "grad_norm": 68.4736328125,
      "learning_rate": 1.998076882146637e-05,
      "loss": 0.4024,
      "step": 830
    },
    {
      "epoch": 0.5937777777777777,
      "grad_norm": 17.022554397583008,
      "learning_rate": 1.9979200101524844e-05,
      "loss": 0.1141,
      "step": 835
    },
    {
      "epoch": 0.5973333333333334,
      "grad_norm": 2.1221814155578613,
      "learning_rate": 1.9977569950151848e-05,
      "loss": 0.3746,
      "step": 840
    },
    {
      "epoch": 0.6008888888888889,
      "grad_norm": 23.238235473632812,
      "learning_rate": 1.9975878377382505e-05,
      "loss": 0.188,
      "step": 845
    },
    {
      "epoch": 0.6044444444444445,
      "grad_norm": 57.049739837646484,
      "learning_rate": 1.997412539363005e-05,
      "loss": 0.222,
      "step": 850
    },
    {
      "epoch": 0.608,
      "grad_norm": 49.909141540527344,
      "learning_rate": 1.9972311009685753e-05,
      "loss": 0.3128,
      "step": 855
    },
    {
      "epoch": 0.6115555555555555,
      "grad_norm": 50.07534408569336,
      "learning_rate": 1.997043523671887e-05,
      "loss": 0.3572,
      "step": 860
    },
    {
      "epoch": 0.6151111111111112,
      "grad_norm": 37.229278564453125,
      "learning_rate": 1.9968498086276565e-05,
      "loss": 0.5168,
      "step": 865
    },
    {
      "epoch": 0.6186666666666667,
      "grad_norm": 1.513396978378296,
      "learning_rate": 1.996649957028383e-05,
      "loss": 0.201,
      "step": 870
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 20.987503051757812,
      "learning_rate": 1.9964439701043422e-05,
      "loss": 0.1118,
      "step": 875
    },
    {
      "epoch": 0.6257777777777778,
      "grad_norm": 39.5469856262207,
      "learning_rate": 1.9962318491235795e-05,
      "loss": 0.2608,
      "step": 880
    },
    {
      "epoch": 0.6293333333333333,
      "grad_norm": 11.383951187133789,
      "learning_rate": 1.9960135953918996e-05,
      "loss": 0.2053,
      "step": 885
    },
    {
      "epoch": 0.6328888888888888,
      "grad_norm": 59.172218322753906,
      "learning_rate": 1.995789210252862e-05,
      "loss": 0.1337,
      "step": 890
    },
    {
      "epoch": 0.6364444444444445,
      "grad_norm": 35.58428955078125,
      "learning_rate": 1.9955586950877693e-05,
      "loss": 0.4863,
      "step": 895
    },
    {
      "epoch": 0.64,
      "grad_norm": 55.85548400878906,
      "learning_rate": 1.9953220513156604e-05,
      "loss": 0.2165,
      "step": 900
    },
    {
      "epoch": 0.64,
      "eval_accuracy": 0.941,
      "eval_f1": 0.9426850592578201,
      "eval_loss": 0.2532116770744324,
      "eval_precision": 0.9165092557612391,
      "eval_recall": 0.9704,
      "eval_roc_auc": 0.9905650399999999,
      "eval_runtime": 616.5095,
      "eval_samples_per_second": 8.11,
      "eval_steps_per_second": 0.508,
      "step": 900
    },
    {
      "epoch": 0.6435555555555555,
      "grad_norm": 36.99977493286133,
      "learning_rate": 1.9950792803933024e-05,
      "loss": 0.3784,
      "step": 905
    },
    {
      "epoch": 0.6471111111111111,
      "grad_norm": 25.826858520507812,
      "learning_rate": 1.9948303838151805e-05,
      "loss": 0.1243,
      "step": 910
    },
    {
      "epoch": 0.6506666666666666,
      "grad_norm": 2.9413909912109375,
      "learning_rate": 1.9945753631134884e-05,
      "loss": 0.2043,
      "step": 915
    },
    {
      "epoch": 0.6542222222222223,
      "grad_norm": 38.90449905395508,
      "learning_rate": 1.9943142198581203e-05,
      "loss": 0.3189,
      "step": 920
    },
    {
      "epoch": 0.6577777777777778,
      "grad_norm": 34.86366271972656,
      "learning_rate": 1.9940469556566612e-05,
      "loss": 0.3001,
      "step": 925
    },
    {
      "epoch": 0.6613333333333333,
      "grad_norm": 14.526966094970703,
      "learning_rate": 1.9937735721543742e-05,
      "loss": 0.1169,
      "step": 930
    },
    {
      "epoch": 0.6648888888888889,
      "grad_norm": 5.871160984039307,
      "learning_rate": 1.9934940710341942e-05,
      "loss": 0.0664,
      "step": 935
    },
    {
      "epoch": 0.6684444444444444,
      "grad_norm": 46.10857391357422,
      "learning_rate": 1.993208454016716e-05,
      "loss": 0.1533,
      "step": 940
    },
    {
      "epoch": 0.672,
      "grad_norm": 22.042757034301758,
      "learning_rate": 1.992916722860182e-05,
      "loss": 0.1811,
      "step": 945
    },
    {
      "epoch": 0.6755555555555556,
      "grad_norm": 33.282894134521484,
      "learning_rate": 1.992618879360475e-05,
      "loss": 0.1865,
      "step": 950
    },
    {
      "epoch": 0.6791111111111111,
      "grad_norm": 60.23435592651367,
      "learning_rate": 1.9923149253511028e-05,
      "loss": 0.4264,
      "step": 955
    },
    {
      "epoch": 0.6826666666666666,
      "grad_norm": 38.40011215209961,
      "learning_rate": 1.9920048627031915e-05,
      "loss": 0.0832,
      "step": 960
    },
    {
      "epoch": 0.6862222222222222,
      "grad_norm": 26.662242889404297,
      "learning_rate": 1.991688693325469e-05,
      "loss": 0.2235,
      "step": 965
    },
    {
      "epoch": 0.6897777777777778,
      "grad_norm": 24.531044006347656,
      "learning_rate": 1.9913664191642587e-05,
      "loss": 0.1847,
      "step": 970
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 21.217660903930664,
      "learning_rate": 1.9910380422034627e-05,
      "loss": 0.2042,
      "step": 975
    },
    {
      "epoch": 0.6968888888888889,
      "grad_norm": 3.40928053855896,
      "learning_rate": 1.9907035644645524e-05,
      "loss": 0.1348,
      "step": 980
    },
    {
      "epoch": 0.7004444444444444,
      "grad_norm": 36.54404830932617,
      "learning_rate": 1.9903629880065555e-05,
      "loss": 0.4595,
      "step": 985
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.022319400683045387,
      "learning_rate": 1.9900163149260424e-05,
      "loss": 0.1084,
      "step": 990
    },
    {
      "epoch": 0.7075555555555556,
      "grad_norm": 31.220624923706055,
      "learning_rate": 1.9896635473571145e-05,
      "loss": 0.2212,
      "step": 995
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 24.955896377563477,
      "learning_rate": 1.9893046874713903e-05,
      "loss": 0.0962,
      "step": 1000
    },
    {
      "epoch": 0.7111111111111111,
      "eval_accuracy": 0.9482,
      "eval_f1": 0.9458498850094085,
      "eval_loss": 0.3039567768573761,
      "eval_precision": 0.9908015768725361,
      "eval_recall": 0.9048,
      "eval_roc_auc": 0.98912208,
      "eval_runtime": 616.4774,
      "eval_samples_per_second": 8.111,
      "eval_steps_per_second": 0.508,
      "step": 1000
    },
    {
      "epoch": 0.7146666666666667,
      "grad_norm": 20.860700607299805,
      "learning_rate": 1.9889397374779927e-05,
      "loss": 0.2313,
      "step": 1005
    },
    {
      "epoch": 0.7182222222222222,
      "grad_norm": 27.45895004272461,
      "learning_rate": 1.9885686996235348e-05,
      "loss": 0.2589,
      "step": 1010
    },
    {
      "epoch": 0.7217777777777777,
      "grad_norm": 8.385116577148438,
      "learning_rate": 1.9881915761921052e-05,
      "loss": 0.2673,
      "step": 1015
    },
    {
      "epoch": 0.7253333333333334,
      "grad_norm": 64.7330322265625,
      "learning_rate": 1.9878083695052572e-05,
      "loss": 0.3576,
      "step": 1020
    },
    {
      "epoch": 0.7288888888888889,
      "grad_norm": 14.286947250366211,
      "learning_rate": 1.98741908192199e-05,
      "loss": 0.0488,
      "step": 1025
    },
    {
      "epoch": 0.7324444444444445,
      "grad_norm": 50.98638916015625,
      "learning_rate": 1.9870237158387385e-05,
      "loss": 0.282,
      "step": 1030
    },
    {
      "epoch": 0.736,
      "grad_norm": 36.21091079711914,
      "learning_rate": 1.9866222736893544e-05,
      "loss": 0.2059,
      "step": 1035
    },
    {
      "epoch": 0.7395555555555555,
      "grad_norm": 93.0669937133789,
      "learning_rate": 1.9862147579450953e-05,
      "loss": 0.3731,
      "step": 1040
    },
    {
      "epoch": 0.7431111111111111,
      "grad_norm": 22.207351684570312,
      "learning_rate": 1.9858011711146062e-05,
      "loss": 0.2335,
      "step": 1045
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 40.7091064453125,
      "learning_rate": 1.9853815157439065e-05,
      "loss": 0.1426,
      "step": 1050
    },
    {
      "epoch": 0.7502222222222222,
      "grad_norm": 58.175662994384766,
      "learning_rate": 1.9849557944163723e-05,
      "loss": 0.3499,
      "step": 1055
    },
    {
      "epoch": 0.7537777777777778,
      "grad_norm": 7.916833400726318,
      "learning_rate": 1.984524009752721e-05,
      "loss": 0.0853,
      "step": 1060
    },
    {
      "epoch": 0.7573333333333333,
      "grad_norm": 46.3337287902832,
      "learning_rate": 1.9840861644109977e-05,
      "loss": 0.2988,
      "step": 1065
    },
    {
      "epoch": 0.7608888888888888,
      "grad_norm": 35.098289489746094,
      "learning_rate": 1.9836422610865544e-05,
      "loss": 0.1008,
      "step": 1070
    },
    {
      "epoch": 0.7644444444444445,
      "grad_norm": 32.7951545715332,
      "learning_rate": 1.9831923025120367e-05,
      "loss": 0.1712,
      "step": 1075
    },
    {
      "epoch": 0.768,
      "grad_norm": 16.897899627685547,
      "learning_rate": 1.982736291457366e-05,
      "loss": 0.0962,
      "step": 1080
    },
    {
      "epoch": 0.7715555555555556,
      "grad_norm": 11.814967155456543,
      "learning_rate": 1.982274230729723e-05,
      "loss": 0.2399,
      "step": 1085
    },
    {
      "epoch": 0.7751111111111111,
      "grad_norm": 52.27188491821289,
      "learning_rate": 1.981806123173528e-05,
      "loss": 0.1407,
      "step": 1090
    },
    {
      "epoch": 0.7786666666666666,
      "grad_norm": 2.997490882873535,
      "learning_rate": 1.9813319716704278e-05,
      "loss": 0.1098,
      "step": 1095
    },
    {
      "epoch": 0.7822222222222223,
      "grad_norm": 39.00629806518555,
      "learning_rate": 1.980851779139273e-05,
      "loss": 0.3797,
      "step": 1100
    },
    {
      "epoch": 0.7822222222222223,
      "eval_accuracy": 0.9276,
      "eval_f1": 0.9222508591065293,
      "eval_loss": 0.5582899451255798,
      "eval_precision": 0.9958256029684601,
      "eval_recall": 0.8588,
      "eval_roc_auc": 0.9896611200000001,
      "eval_runtime": 617.8852,
      "eval_samples_per_second": 8.092,
      "eval_steps_per_second": 0.507,
      "step": 1100
    },
    {
      "epoch": 0.7857777777777778,
      "grad_norm": 51.4522819519043,
      "learning_rate": 1.9803655485361048e-05,
      "loss": 0.2516,
      "step": 1105
    },
    {
      "epoch": 0.7893333333333333,
      "grad_norm": 25.291439056396484,
      "learning_rate": 1.9798732828541325e-05,
      "loss": 0.2937,
      "step": 1110
    },
    {
      "epoch": 0.7928888888888889,
      "grad_norm": 0.32229703664779663,
      "learning_rate": 1.979374985123718e-05,
      "loss": 0.0461,
      "step": 1115
    },
    {
      "epoch": 0.7964444444444444,
      "grad_norm": 20.884550094604492,
      "learning_rate": 1.9788706584123555e-05,
      "loss": 0.1813,
      "step": 1120
    },
    {
      "epoch": 0.8,
      "grad_norm": 17.072450637817383,
      "learning_rate": 1.9783603058246542e-05,
      "loss": 0.4228,
      "step": 1125
    },
    {
      "epoch": 0.8035555555555556,
      "grad_norm": 27.050125122070312,
      "learning_rate": 1.9778439305023175e-05,
      "loss": 0.1841,
      "step": 1130
    },
    {
      "epoch": 0.8071111111111111,
      "grad_norm": 61.038631439208984,
      "learning_rate": 1.9773215356241255e-05,
      "loss": 0.3295,
      "step": 1135
    },
    {
      "epoch": 0.8106666666666666,
      "grad_norm": 12.550230026245117,
      "learning_rate": 1.9767931244059126e-05,
      "loss": 0.2291,
      "step": 1140
    },
    {
      "epoch": 0.8142222222222222,
      "grad_norm": 46.01909255981445,
      "learning_rate": 1.976258700100551e-05,
      "loss": 0.1525,
      "step": 1145
    },
    {
      "epoch": 0.8177777777777778,
      "grad_norm": 28.116655349731445,
      "learning_rate": 1.975718265997929e-05,
      "loss": 0.1411,
      "step": 1150
    },
    {
      "epoch": 0.8213333333333334,
      "grad_norm": 35.6562385559082,
      "learning_rate": 1.9751718254249294e-05,
      "loss": 0.3373,
      "step": 1155
    },
    {
      "epoch": 0.8248888888888889,
      "grad_norm": 42.56007385253906,
      "learning_rate": 1.9746193817454128e-05,
      "loss": 0.2716,
      "step": 1160
    },
    {
      "epoch": 0.8284444444444444,
      "grad_norm": 45.2736701965332,
      "learning_rate": 1.9740609383601933e-05,
      "loss": 0.2289,
      "step": 1165
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.05056452006101608,
      "learning_rate": 1.9734964987070185e-05,
      "loss": 0.1892,
      "step": 1170
    },
    {
      "epoch": 0.8355555555555556,
      "grad_norm": 10.439630508422852,
      "learning_rate": 1.9729260662605497e-05,
      "loss": 0.2297,
      "step": 1175
    },
    {
      "epoch": 0.8391111111111111,
      "grad_norm": 1.118918776512146,
      "learning_rate": 1.9723496445323385e-05,
      "loss": 0.0144,
      "step": 1180
    },
    {
      "epoch": 0.8426666666666667,
      "grad_norm": 27.070199966430664,
      "learning_rate": 1.9717672370708075e-05,
      "loss": 0.1193,
      "step": 1185
    },
    {
      "epoch": 0.8462222222222222,
      "grad_norm": 55.689640045166016,
      "learning_rate": 1.9711788474612263e-05,
      "loss": 0.4457,
      "step": 1190
    },
    {
      "epoch": 0.8497777777777777,
      "grad_norm": 22.08765983581543,
      "learning_rate": 1.97058447932569e-05,
      "loss": 0.0427,
      "step": 1195
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 78.25968933105469,
      "learning_rate": 1.969984136323098e-05,
      "loss": 0.2236,
      "step": 1200
    },
    {
      "epoch": 0.8533333333333334,
      "eval_accuracy": 0.9404,
      "eval_f1": 0.9424265842349304,
      "eval_loss": 0.28947481513023376,
      "eval_precision": 0.9114349775784754,
      "eval_recall": 0.9756,
      "eval_roc_auc": 0.99219312,
      "eval_runtime": 618.6621,
      "eval_samples_per_second": 8.082,
      "eval_steps_per_second": 0.506,
      "step": 1200
    },
    {
      "epoch": 0.8568888888888889,
      "grad_norm": 40.80272674560547,
      "learning_rate": 1.96937782214913e-05,
      "loss": 0.3897,
      "step": 1205
    },
    {
      "epoch": 0.8604444444444445,
      "grad_norm": 68.95394134521484,
      "learning_rate": 1.968765540536224e-05,
      "loss": 0.2158,
      "step": 1210
    },
    {
      "epoch": 0.864,
      "grad_norm": 48.89760208129883,
      "learning_rate": 1.9681472952535544e-05,
      "loss": 0.3856,
      "step": 1215
    },
    {
      "epoch": 0.8675555555555555,
      "grad_norm": 21.733549118041992,
      "learning_rate": 1.9675230901070058e-05,
      "loss": 0.1508,
      "step": 1220
    },
    {
      "epoch": 0.8711111111111111,
      "grad_norm": 2.4615297317504883,
      "learning_rate": 1.9668929289391524e-05,
      "loss": 0.111,
      "step": 1225
    },
    {
      "epoch": 0.8746666666666667,
      "grad_norm": 27.38258171081543,
      "learning_rate": 1.9662568156292334e-05,
      "loss": 0.2558,
      "step": 1230
    },
    {
      "epoch": 0.8782222222222222,
      "grad_norm": 32.314266204833984,
      "learning_rate": 1.9656147540931288e-05,
      "loss": 0.1228,
      "step": 1235
    },
    {
      "epoch": 0.8817777777777778,
      "grad_norm": 63.76972579956055,
      "learning_rate": 1.9649667482833356e-05,
      "loss": 0.1835,
      "step": 1240
    },
    {
      "epoch": 0.8853333333333333,
      "grad_norm": 2.1644656658172607,
      "learning_rate": 1.964312802188944e-05,
      "loss": 0.1107,
      "step": 1245
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 7.393912315368652,
      "learning_rate": 1.9636529198356112e-05,
      "loss": 0.0703,
      "step": 1250
    },
    {
      "epoch": 0.8924444444444445,
      "grad_norm": 1.837188720703125,
      "learning_rate": 1.962987105285539e-05,
      "loss": 0.2432,
      "step": 1255
    },
    {
      "epoch": 0.896,
      "grad_norm": 18.14742088317871,
      "learning_rate": 1.9623153626374458e-05,
      "loss": 0.0597,
      "step": 1260
    },
    {
      "epoch": 0.8995555555555556,
      "grad_norm": 42.66085433959961,
      "learning_rate": 1.9616376960265445e-05,
      "loss": 0.2516,
      "step": 1265
    },
    {
      "epoch": 0.9031111111111111,
      "grad_norm": 94.1565170288086,
      "learning_rate": 1.9609541096245153e-05,
      "loss": 0.2773,
      "step": 1270
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 15.828038215637207,
      "learning_rate": 1.9602646076394806e-05,
      "loss": 0.1767,
      "step": 1275
    },
    {
      "epoch": 0.9102222222222223,
      "grad_norm": 30.21733283996582,
      "learning_rate": 1.9595691943159777e-05,
      "loss": 0.238,
      "step": 1280
    },
    {
      "epoch": 0.9137777777777778,
      "grad_norm": 28.096389770507812,
      "learning_rate": 1.9588678739349345e-05,
      "loss": 0.2402,
      "step": 1285
    },
    {
      "epoch": 0.9173333333333333,
      "grad_norm": 0.9046257734298706,
      "learning_rate": 1.9581606508136426e-05,
      "loss": 0.2334,
      "step": 1290
    },
    {
      "epoch": 0.9208888888888889,
      "grad_norm": 23.665382385253906,
      "learning_rate": 1.95744752930573e-05,
      "loss": 0.1413,
      "step": 1295
    },
    {
      "epoch": 0.9244444444444444,
      "grad_norm": 15.732418060302734,
      "learning_rate": 1.9567285138011365e-05,
      "loss": 0.0617,
      "step": 1300
    },
    {
      "epoch": 0.9244444444444444,
      "eval_accuracy": 0.959,
      "eval_f1": 0.9577232419055475,
      "eval_loss": 0.21791957318782806,
      "eval_precision": 0.9885057471264368,
      "eval_recall": 0.9288,
      "eval_roc_auc": 0.9926876800000001,
      "eval_runtime": 617.2862,
      "eval_samples_per_second": 8.1,
      "eval_steps_per_second": 0.507,
      "step": 1300
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.2147689163684845,
      "learning_rate": 1.956003608726082e-05,
      "loss": 0.2935,
      "step": 1305
    },
    {
      "epoch": 0.9315555555555556,
      "grad_norm": 10.59455394744873,
      "learning_rate": 1.9552728185430454e-05,
      "loss": 0.05,
      "step": 1310
    },
    {
      "epoch": 0.9351111111111111,
      "grad_norm": 5.735363006591797,
      "learning_rate": 1.954536147750732e-05,
      "loss": 0.0184,
      "step": 1315
    },
    {
      "epoch": 0.9386666666666666,
      "grad_norm": 32.88113021850586,
      "learning_rate": 1.953793600884049e-05,
      "loss": 0.0883,
      "step": 1320
    },
    {
      "epoch": 0.9422222222222222,
      "grad_norm": 26.889375686645508,
      "learning_rate": 1.9530451825140752e-05,
      "loss": 0.1258,
      "step": 1325
    },
    {
      "epoch": 0.9457777777777778,
      "grad_norm": 30.658924102783203,
      "learning_rate": 1.952290897248035e-05,
      "loss": 0.1394,
      "step": 1330
    },
    {
      "epoch": 0.9493333333333334,
      "grad_norm": 37.06431579589844,
      "learning_rate": 1.951530749729269e-05,
      "loss": 0.079,
      "step": 1335
    },
    {
      "epoch": 0.9528888888888889,
      "grad_norm": 24.817790985107422,
      "learning_rate": 1.9507647446372056e-05,
      "loss": 0.1564,
      "step": 1340
    },
    {
      "epoch": 0.9564444444444444,
      "grad_norm": 19.99738883972168,
      "learning_rate": 1.9499928866873318e-05,
      "loss": 0.1487,
      "step": 1345
    },
    {
      "epoch": 0.96,
      "grad_norm": 30.619850158691406,
      "learning_rate": 1.949215180631164e-05,
      "loss": 0.1967,
      "step": 1350
    },
    {
      "epoch": 0.9635555555555556,
      "grad_norm": 34.16566848754883,
      "learning_rate": 1.9484316312562204e-05,
      "loss": 0.2977,
      "step": 1355
    },
    {
      "epoch": 0.9671111111111111,
      "grad_norm": 0.7793286442756653,
      "learning_rate": 1.94764224338599e-05,
      "loss": 0.1348,
      "step": 1360
    },
    {
      "epoch": 0.9706666666666667,
      "grad_norm": 22.2725887298584,
      "learning_rate": 1.9468470218799025e-05,
      "loss": 0.1774,
      "step": 1365
    },
    {
      "epoch": 0.9742222222222222,
      "grad_norm": 2.6051692962646484,
      "learning_rate": 1.9460459716333e-05,
      "loss": 0.1955,
      "step": 1370
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 22.733261108398438,
      "learning_rate": 1.9452390975774054e-05,
      "loss": 0.358,
      "step": 1375
    },
    {
      "epoch": 0.9813333333333333,
      "grad_norm": 0.7902578115463257,
      "learning_rate": 1.9444264046792934e-05,
      "loss": 0.1366,
      "step": 1380
    },
    {
      "epoch": 0.9848888888888889,
      "grad_norm": 7.124425411224365,
      "learning_rate": 1.9436078979418584e-05,
      "loss": 0.1762,
      "step": 1385
    },
    {
      "epoch": 0.9884444444444445,
      "grad_norm": 21.068206787109375,
      "learning_rate": 1.9427835824037852e-05,
      "loss": 0.1208,
      "step": 1390
    },
    {
      "epoch": 0.992,
      "grad_norm": 18.1085205078125,
      "learning_rate": 1.941953463139517e-05,
      "loss": 0.3824,
      "step": 1395
    },
    {
      "epoch": 0.9955555555555555,
      "grad_norm": 36.7384147644043,
      "learning_rate": 1.9411175452592238e-05,
      "loss": 0.1701,
      "step": 1400
    },
    {
      "epoch": 0.9955555555555555,
      "eval_accuracy": 0.9578,
      "eval_f1": 0.9587810119163899,
      "eval_loss": 0.16406188905239105,
      "eval_precision": 0.9369988545246277,
      "eval_recall": 0.9816,
      "eval_roc_auc": 0.9946373599999999,
      "eval_runtime": 617.9833,
      "eval_samples_per_second": 8.091,
      "eval_steps_per_second": 0.506,
      "step": 1400
    },
    {
      "epoch": 0.9991111111111111,
      "grad_norm": 20.37067985534668,
      "learning_rate": 1.9402758339087728e-05,
      "loss": 0.1009,
      "step": 1405
    },
    {
      "epoch": 1.0021333333333333,
      "grad_norm": 0.1661641001701355,
      "learning_rate": 1.9394283342696945e-05,
      "loss": 0.0536,
      "step": 1410
    },
    {
      "epoch": 1.0056888888888889,
      "grad_norm": 2.0251665115356445,
      "learning_rate": 1.9385750515591523e-05,
      "loss": 0.1308,
      "step": 1415
    },
    {
      "epoch": 1.0092444444444444,
      "grad_norm": 0.44790735840797424,
      "learning_rate": 1.9377159910299094e-05,
      "loss": 0.0161,
      "step": 1420
    },
    {
      "epoch": 1.0128,
      "grad_norm": 8.203470230102539,
      "learning_rate": 1.936851157970298e-05,
      "loss": 0.0556,
      "step": 1425
    },
    {
      "epoch": 1.0163555555555555,
      "grad_norm": 0.20745620131492615,
      "learning_rate": 1.935980557704184e-05,
      "loss": 0.0859,
      "step": 1430
    },
    {
      "epoch": 1.0199111111111112,
      "grad_norm": 29.693323135375977,
      "learning_rate": 1.9351041955909377e-05,
      "loss": 0.0862,
      "step": 1435
    },
    {
      "epoch": 1.0234666666666667,
      "grad_norm": 23.296981811523438,
      "learning_rate": 1.934222077025398e-05,
      "loss": 0.2494,
      "step": 1440
    },
    {
      "epoch": 1.0270222222222223,
      "grad_norm": 4.411466121673584,
      "learning_rate": 1.9333342074378402e-05,
      "loss": 0.0478,
      "step": 1445
    },
    {
      "epoch": 1.0305777777777778,
      "grad_norm": 2.2196342945098877,
      "learning_rate": 1.9324405922939427e-05,
      "loss": 0.0323,
      "step": 1450
    },
    {
      "epoch": 1.0341333333333333,
      "grad_norm": 19.238834381103516,
      "learning_rate": 1.931541237094754e-05,
      "loss": 0.1062,
      "step": 1455
    },
    {
      "epoch": 1.0376888888888889,
      "grad_norm": 0.0639217272400856,
      "learning_rate": 1.930636147376657e-05,
      "loss": 0.0563,
      "step": 1460
    },
    {
      "epoch": 1.0412444444444444,
      "grad_norm": 19.33419418334961,
      "learning_rate": 1.9297253287113368e-05,
      "loss": 0.1539,
      "step": 1465
    },
    {
      "epoch": 1.0448,
      "grad_norm": 15.16878604888916,
      "learning_rate": 1.9288087867057447e-05,
      "loss": 0.0713,
      "step": 1470
    },
    {
      "epoch": 1.0483555555555555,
      "grad_norm": 0.007802451029419899,
      "learning_rate": 1.9278865270020656e-05,
      "loss": 0.0849,
      "step": 1475
    },
    {
      "epoch": 1.051911111111111,
      "grad_norm": 0.0018691752338781953,
      "learning_rate": 1.9269585552776813e-05,
      "loss": 0.053,
      "step": 1480
    },
    {
      "epoch": 1.0554666666666668,
      "grad_norm": 22.247718811035156,
      "learning_rate": 1.9260248772451378e-05,
      "loss": 0.1206,
      "step": 1485
    },
    {
      "epoch": 1.0590222222222223,
      "grad_norm": 3.922215700149536,
      "learning_rate": 1.9250854986521072e-05,
      "loss": 0.0403,
      "step": 1490
    },
    {
      "epoch": 1.0625777777777778,
      "grad_norm": 5.35969352722168,
      "learning_rate": 1.924140425281355e-05,
      "loss": 0.0786,
      "step": 1495
    },
    {
      "epoch": 1.0661333333333334,
      "grad_norm": 21.04631805419922,
      "learning_rate": 1.9231896629507033e-05,
      "loss": 0.1061,
      "step": 1500
    },
    {
      "epoch": 1.0661333333333334,
      "eval_accuracy": 0.9704,
      "eval_f1": 0.970281124497992,
      "eval_loss": 0.1446542739868164,
      "eval_precision": 0.9741935483870968,
      "eval_recall": 0.9664,
      "eval_roc_auc": 0.99491752,
      "eval_runtime": 617.8934,
      "eval_samples_per_second": 8.092,
      "eval_steps_per_second": 0.507,
      "step": 1500
    },
    {
      "epoch": 1.069688888888889,
      "grad_norm": 23.53091049194336,
      "learning_rate": 1.9222332175129952e-05,
      "loss": 0.0849,
      "step": 1505
    },
    {
      "epoch": 1.0732444444444444,
      "grad_norm": 1.9933260679244995,
      "learning_rate": 1.9212710948560584e-05,
      "loss": 0.2414,
      "step": 1510
    },
    {
      "epoch": 1.0768,
      "grad_norm": 0.9347159266471863,
      "learning_rate": 1.9203033009026687e-05,
      "loss": 0.199,
      "step": 1515
    },
    {
      "epoch": 1.0803555555555555,
      "grad_norm": 48.88674545288086,
      "learning_rate": 1.9193298416105165e-05,
      "loss": 0.1422,
      "step": 1520
    },
    {
      "epoch": 1.083911111111111,
      "grad_norm": 0.01493274886161089,
      "learning_rate": 1.9183507229721643e-05,
      "loss": 0.1492,
      "step": 1525
    },
    {
      "epoch": 1.0874666666666666,
      "grad_norm": 7.40112829208374,
      "learning_rate": 1.917365951015016e-05,
      "loss": 0.0214,
      "step": 1530
    },
    {
      "epoch": 1.0910222222222221,
      "grad_norm": 0.02457001991569996,
      "learning_rate": 1.916375531801276e-05,
      "loss": 0.0428,
      "step": 1535
    },
    {
      "epoch": 1.0945777777777779,
      "grad_norm": 28.033161163330078,
      "learning_rate": 1.9153794714279127e-05,
      "loss": 0.223,
      "step": 1540
    },
    {
      "epoch": 1.0981333333333334,
      "grad_norm": 0.5068085789680481,
      "learning_rate": 1.914377776026621e-05,
      "loss": 0.0375,
      "step": 1545
    },
    {
      "epoch": 1.101688888888889,
      "grad_norm": 15.182334899902344,
      "learning_rate": 1.913370451763786e-05,
      "loss": 0.0304,
      "step": 1550
    },
    {
      "epoch": 1.1052444444444445,
      "grad_norm": 9.411516189575195,
      "learning_rate": 1.9123575048404422e-05,
      "loss": 0.1468,
      "step": 1555
    },
    {
      "epoch": 1.1088,
      "grad_norm": 9.38680648803711,
      "learning_rate": 1.9113389414922385e-05,
      "loss": 0.1129,
      "step": 1560
    },
    {
      "epoch": 1.1123555555555555,
      "grad_norm": 21.920856475830078,
      "learning_rate": 1.9103147679893962e-05,
      "loss": 0.2805,
      "step": 1565
    },
    {
      "epoch": 1.115911111111111,
      "grad_norm": 9.272247314453125,
      "learning_rate": 1.9092849906366747e-05,
      "loss": 0.0461,
      "step": 1570
    },
    {
      "epoch": 1.1194666666666666,
      "grad_norm": 31.077152252197266,
      "learning_rate": 1.9082496157733284e-05,
      "loss": 0.0198,
      "step": 1575
    },
    {
      "epoch": 1.1230222222222221,
      "grad_norm": 8.151458740234375,
      "learning_rate": 1.9072086497730714e-05,
      "loss": 0.0805,
      "step": 1580
    },
    {
      "epoch": 1.126577777777778,
      "grad_norm": 48.314476013183594,
      "learning_rate": 1.9061620990440347e-05,
      "loss": 0.2198,
      "step": 1585
    },
    {
      "epoch": 1.1301333333333332,
      "grad_norm": 38.2406120300293,
      "learning_rate": 1.9051099700287303e-05,
      "loss": 0.0368,
      "step": 1590
    },
    {
      "epoch": 1.133688888888889,
      "grad_norm": 30.10784339904785,
      "learning_rate": 1.904052269204009e-05,
      "loss": 0.1128,
      "step": 1595
    },
    {
      "epoch": 1.1372444444444445,
      "grad_norm": 55.42192840576172,
      "learning_rate": 1.9029890030810212e-05,
      "loss": 0.2192,
      "step": 1600
    },
    {
      "epoch": 1.1372444444444445,
      "eval_accuracy": 0.9716,
      "eval_f1": 0.9717131474103585,
      "eval_loss": 0.12425322085618973,
      "eval_precision": 0.9678571428571429,
      "eval_recall": 0.9756,
      "eval_roc_auc": 0.99650456,
      "eval_runtime": 618.0837,
      "eval_samples_per_second": 8.09,
      "eval_steps_per_second": 0.506,
      "step": 1600
    },
    {
      "epoch": 1.1408,
      "grad_norm": 55.0172233581543,
      "learning_rate": 1.901920178205178e-05,
      "loss": 0.1333,
      "step": 1605
    },
    {
      "epoch": 1.1443555555555556,
      "grad_norm": 0.20411978662014008,
      "learning_rate": 1.9008458011561083e-05,
      "loss": 0.1411,
      "step": 1610
    },
    {
      "epoch": 1.147911111111111,
      "grad_norm": 38.15242385864258,
      "learning_rate": 1.8997658785476215e-05,
      "loss": 0.0913,
      "step": 1615
    },
    {
      "epoch": 1.1514666666666666,
      "grad_norm": 1.2720727920532227,
      "learning_rate": 1.8986804170276638e-05,
      "loss": 0.0735,
      "step": 1620
    },
    {
      "epoch": 1.1550222222222222,
      "grad_norm": 16.128759384155273,
      "learning_rate": 1.8975894232782797e-05,
      "loss": 0.1652,
      "step": 1625
    },
    {
      "epoch": 1.1585777777777777,
      "grad_norm": 29.91068458557129,
      "learning_rate": 1.8964929040155692e-05,
      "loss": 0.1255,
      "step": 1630
    },
    {
      "epoch": 1.1621333333333332,
      "grad_norm": 19.070541381835938,
      "learning_rate": 1.8953908659896478e-05,
      "loss": 0.1098,
      "step": 1635
    },
    {
      "epoch": 1.165688888888889,
      "grad_norm": 32.2443733215332,
      "learning_rate": 1.8942833159846025e-05,
      "loss": 0.0726,
      "step": 1640
    },
    {
      "epoch": 1.1692444444444445,
      "grad_norm": 45.89453887939453,
      "learning_rate": 1.8931702608184543e-05,
      "loss": 0.1774,
      "step": 1645
    },
    {
      "epoch": 1.1728,
      "grad_norm": 9.655502319335938,
      "learning_rate": 1.8920517073431112e-05,
      "loss": 0.0172,
      "step": 1650
    },
    {
      "epoch": 1.1763555555555556,
      "grad_norm": 5.32438325881958,
      "learning_rate": 1.8909276624443303e-05,
      "loss": 0.1108,
      "step": 1655
    },
    {
      "epoch": 1.1799111111111111,
      "grad_norm": 1.110581398010254,
      "learning_rate": 1.8897981330416727e-05,
      "loss": 0.002,
      "step": 1660
    },
    {
      "epoch": 1.1834666666666667,
      "grad_norm": 20.31671142578125,
      "learning_rate": 1.888663126088462e-05,
      "loss": 0.0342,
      "step": 1665
    },
    {
      "epoch": 1.1870222222222222,
      "grad_norm": 28.793445587158203,
      "learning_rate": 1.887522648571742e-05,
      "loss": 0.1344,
      "step": 1670
    },
    {
      "epoch": 1.1905777777777777,
      "grad_norm": 10.858373641967773,
      "learning_rate": 1.8863767075122312e-05,
      "loss": 0.1049,
      "step": 1675
    },
    {
      "epoch": 1.1941333333333333,
      "grad_norm": 7.236496925354004,
      "learning_rate": 1.8852253099642835e-05,
      "loss": 0.0931,
      "step": 1680
    },
    {
      "epoch": 1.1976888888888888,
      "grad_norm": 44.49000930786133,
      "learning_rate": 1.884068463015841e-05,
      "loss": 0.1957,
      "step": 1685
    },
    {
      "epoch": 1.2012444444444443,
      "grad_norm": 16.23662757873535,
      "learning_rate": 1.8829061737883935e-05,
      "loss": 0.0367,
      "step": 1690
    },
    {
      "epoch": 1.2048,
      "grad_norm": 5.19316291809082,
      "learning_rate": 1.881738449436932e-05,
      "loss": 0.1364,
      "step": 1695
    },
    {
      "epoch": 1.2083555555555556,
      "grad_norm": 17.95043182373047,
      "learning_rate": 1.880565297149906e-05,
      "loss": 0.2013,
      "step": 1700
    },
    {
      "epoch": 1.2083555555555556,
      "eval_accuracy": 0.9634,
      "eval_f1": 0.96272153188022,
      "eval_loss": 0.17901650071144104,
      "eval_precision": 0.9809049398090494,
      "eval_recall": 0.9452,
      "eval_roc_auc": 0.99389232,
      "eval_runtime": 618.5578,
      "eval_samples_per_second": 8.083,
      "eval_steps_per_second": 0.506,
      "step": 1700
    },
    {
      "epoch": 1.2119111111111112,
      "grad_norm": 21.02923011779785,
      "learning_rate": 1.87938672414918e-05,
      "loss": 0.1326,
      "step": 1705
    },
    {
      "epoch": 1.2154666666666667,
      "grad_norm": 17.70196533203125,
      "learning_rate": 1.8782027376899868e-05,
      "loss": 0.118,
      "step": 1710
    },
    {
      "epoch": 1.2190222222222222,
      "grad_norm": 6.695098400115967,
      "learning_rate": 1.877013345060885e-05,
      "loss": 0.1191,
      "step": 1715
    },
    {
      "epoch": 1.2225777777777778,
      "grad_norm": 13.287690162658691,
      "learning_rate": 1.8758185535837134e-05,
      "loss": 0.0463,
      "step": 1720
    },
    {
      "epoch": 1.2261333333333333,
      "grad_norm": 53.20762252807617,
      "learning_rate": 1.874618370613545e-05,
      "loss": 0.2825,
      "step": 1725
    },
    {
      "epoch": 1.2296888888888888,
      "grad_norm": 28.480024337768555,
      "learning_rate": 1.8734128035386442e-05,
      "loss": 0.0492,
      "step": 1730
    },
    {
      "epoch": 1.2332444444444444,
      "grad_norm": 97.94824981689453,
      "learning_rate": 1.8722018597804176e-05,
      "loss": 0.3614,
      "step": 1735
    },
    {
      "epoch": 1.2368000000000001,
      "grad_norm": 8.762274742126465,
      "learning_rate": 1.8709855467933715e-05,
      "loss": 0.1539,
      "step": 1740
    },
    {
      "epoch": 1.2403555555555554,
      "grad_norm": 0.0004906484391540289,
      "learning_rate": 1.8697638720650647e-05,
      "loss": 0.0513,
      "step": 1745
    },
    {
      "epoch": 1.2439111111111112,
      "grad_norm": 27.012985229492188,
      "learning_rate": 1.8685368431160632e-05,
      "loss": 0.1351,
      "step": 1750
    },
    {
      "epoch": 1.2474666666666667,
      "grad_norm": 12.372810363769531,
      "learning_rate": 1.867304467499892e-05,
      "loss": 0.1446,
      "step": 1755
    },
    {
      "epoch": 1.2510222222222223,
      "grad_norm": 35.5349006652832,
      "learning_rate": 1.8660667528029906e-05,
      "loss": 0.0564,
      "step": 1760
    },
    {
      "epoch": 1.2545777777777778,
      "grad_norm": 19.583553314208984,
      "learning_rate": 1.8648237066446665e-05,
      "loss": 0.0702,
      "step": 1765
    },
    {
      "epoch": 1.2581333333333333,
      "grad_norm": 0.7653942704200745,
      "learning_rate": 1.8635753366770457e-05,
      "loss": 0.0749,
      "step": 1770
    },
    {
      "epoch": 1.2616888888888889,
      "grad_norm": 3.4680073261260986,
      "learning_rate": 1.8623216505850287e-05,
      "loss": 0.0647,
      "step": 1775
    },
    {
      "epoch": 1.2652444444444444,
      "grad_norm": 1.823462724685669,
      "learning_rate": 1.8610626560862407e-05,
      "loss": 0.0022,
      "step": 1780
    },
    {
      "epoch": 1.2688,
      "grad_norm": 24.758005142211914,
      "learning_rate": 1.859798360930986e-05,
      "loss": 0.1237,
      "step": 1785
    },
    {
      "epoch": 1.2723555555555555,
      "grad_norm": 0.21347741782665253,
      "learning_rate": 1.8585287729021994e-05,
      "loss": 0.0266,
      "step": 1790
    },
    {
      "epoch": 1.2759111111111112,
      "grad_norm": 6.619270324707031,
      "learning_rate": 1.8572538998153975e-05,
      "loss": 0.0248,
      "step": 1795
    },
    {
      "epoch": 1.2794666666666665,
      "grad_norm": 20.427995681762695,
      "learning_rate": 1.8559737495186322e-05,
      "loss": 0.0829,
      "step": 1800
    },
    {
      "epoch": 1.2794666666666665,
      "eval_accuracy": 0.9614,
      "eval_f1": 0.9617746088334324,
      "eval_loss": 0.18242330849170685,
      "eval_precision": 0.9525304040800314,
      "eval_recall": 0.9712,
      "eval_roc_auc": 0.9944776799999999,
      "eval_runtime": 617.4628,
      "eval_samples_per_second": 8.098,
      "eval_steps_per_second": 0.507,
      "step": 1800
    },
    {
      "epoch": 1.2830222222222223,
      "grad_norm": 27.13875389099121,
      "learning_rate": 1.854688329892442e-05,
      "loss": 0.0399,
      "step": 1805
    },
    {
      "epoch": 1.2865777777777778,
      "grad_norm": 25.49225616455078,
      "learning_rate": 1.853397648849802e-05,
      "loss": 0.2156,
      "step": 1810
    },
    {
      "epoch": 1.2901333333333334,
      "grad_norm": 30.716115951538086,
      "learning_rate": 1.8521017143360768e-05,
      "loss": 0.0934,
      "step": 1815
    },
    {
      "epoch": 1.2936888888888889,
      "grad_norm": 22.517410278320312,
      "learning_rate": 1.8508005343289714e-05,
      "loss": 0.0376,
      "step": 1820
    },
    {
      "epoch": 1.2972444444444444,
      "grad_norm": 14.005695343017578,
      "learning_rate": 1.8494941168384817e-05,
      "loss": 0.0586,
      "step": 1825
    },
    {
      "epoch": 1.3008,
      "grad_norm": 1.4039316177368164,
      "learning_rate": 1.848182469906845e-05,
      "loss": 0.1132,
      "step": 1830
    },
    {
      "epoch": 1.3043555555555555,
      "grad_norm": 0.9376311302185059,
      "learning_rate": 1.8468656016084906e-05,
      "loss": 0.0977,
      "step": 1835
    },
    {
      "epoch": 1.3079111111111112,
      "grad_norm": 0.01200898177921772,
      "learning_rate": 1.845543520049991e-05,
      "loss": 0.0223,
      "step": 1840
    },
    {
      "epoch": 1.3114666666666666,
      "grad_norm": 3.267951488494873,
      "learning_rate": 1.844216233370011e-05,
      "loss": 0.0583,
      "step": 1845
    },
    {
      "epoch": 1.3150222222222223,
      "grad_norm": 4.709502696990967,
      "learning_rate": 1.8428837497392566e-05,
      "loss": 0.0422,
      "step": 1850
    },
    {
      "epoch": 1.3185777777777778,
      "grad_norm": 13.844281196594238,
      "learning_rate": 1.8415460773604282e-05,
      "loss": 0.0636,
      "step": 1855
    },
    {
      "epoch": 1.3221333333333334,
      "grad_norm": 0.013823765330016613,
      "learning_rate": 1.8402032244681664e-05,
      "loss": 0.0283,
      "step": 1860
    },
    {
      "epoch": 1.325688888888889,
      "grad_norm": 10.768815994262695,
      "learning_rate": 1.838855199329002e-05,
      "loss": 0.0102,
      "step": 1865
    },
    {
      "epoch": 1.3292444444444445,
      "grad_norm": 26.54950523376465,
      "learning_rate": 1.8375020102413084e-05,
      "loss": 0.0741,
      "step": 1870
    },
    {
      "epoch": 1.3328,
      "grad_norm": 0.00197012210264802,
      "learning_rate": 1.8361436655352456e-05,
      "loss": 0.019,
      "step": 1875
    },
    {
      "epoch": 1.3363555555555555,
      "grad_norm": 39.7972412109375,
      "learning_rate": 1.8347801735727126e-05,
      "loss": 0.0969,
      "step": 1880
    },
    {
      "epoch": 1.339911111111111,
      "grad_norm": 6.211235523223877,
      "learning_rate": 1.8334115427472943e-05,
      "loss": 0.1091,
      "step": 1885
    },
    {
      "epoch": 1.3434666666666666,
      "grad_norm": 18.081539154052734,
      "learning_rate": 1.83203778148421e-05,
      "loss": 0.0934,
      "step": 1890
    },
    {
      "epoch": 1.3470222222222223,
      "grad_norm": 21.375415802001953,
      "learning_rate": 1.8306588982402618e-05,
      "loss": 0.2532,
      "step": 1895
    },
    {
      "epoch": 1.3505777777777777,
      "grad_norm": 0.0003852667286992073,
      "learning_rate": 1.8292749015037826e-05,
      "loss": 0.1061,
      "step": 1900
    },
    {
      "epoch": 1.3505777777777777,
      "eval_accuracy": 0.9714,
      "eval_f1": 0.9709053916581891,
      "eval_loss": 0.16976940631866455,
      "eval_precision": 0.987991718426501,
      "eval_recall": 0.9544,
      "eval_roc_auc": 0.99559064,
      "eval_runtime": 617.709,
      "eval_samples_per_second": 8.094,
      "eval_steps_per_second": 0.507,
      "step": 1900
    },
    {
      "epoch": 1.3505777777777777,
      "step": 1900,
      "total_flos": 1.305664233035268e+18,
      "train_loss": 0.6323473794307364,
      "train_runtime": 29604.2776,
      "train_samples_per_second": 7.6,
      "train_steps_per_second": 0.238
    }
  ],
  "logging_steps": 5,
  "max_steps": 7035,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.001
      },
      "attributes": {
        "early_stopping_patience_counter": 1
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.305664233035268e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
